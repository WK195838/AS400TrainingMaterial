# ç¬¬ä¸ƒæ¨¡çµ„ï¼šéƒ¨ç½²èˆ‡ç¶­è­· (ç¬¬8é€±)

**å­¸ç¿’æ™‚é–“**ï¼šç¬¬8é€± (6-8å°æ™‚)  
**å…ˆä¿®è¦æ±‚**ï¼šå®Œæˆç¬¬å…­æ¨¡çµ„ - è»Ÿé«”æ¸¬è©¦  
**æœ¬é€±é‡é»**ï¼šè»Ÿé«”éƒ¨ç½²ç­–ç•¥èˆ‡ç¶­è­·ç®¡ç†çš„å®Œæ•´é«”ç³»

---

## ğŸ“‹ å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬é€±å­¸ç¿’å¾Œï¼Œæ‚¨å°‡èƒ½å¤ ï¼š

âœ… **æŒæ¡ç¾ä»£è»Ÿé«”éƒ¨ç½²ç­–ç•¥èˆ‡æœ€ä½³å¯¦å‹™**  
âœ… **å»ºç«‹æœ‰æ•ˆçš„ç³»çµ±ç›£æ§èˆ‡æ•ˆèƒ½èª¿æ ¡æ©Ÿåˆ¶**  
âœ… **è¨­è¨ˆå®Œæ•´çš„ç¶­è­·ç®¡ç†æµç¨‹**  
âœ… **å¯¦æ–½ç½é›£æ¢å¾©èˆ‡å‚™ä»½ç­–ç•¥**  
âœ… **å»ºç«‹ä½¿ç”¨è€…æ”¯æ´èˆ‡æ–‡ä»¶ç®¡ç†é«”ç³»**  
âœ… **è¦åŠƒè»Ÿé«”ç”Ÿå‘½é€±æœŸçš„é•·æœŸç¶­è­·**

---

## ğŸ¯ æœ¬é€±å­¸ç¿’è·¯å¾‘

```
éƒ¨ç½²ç­–ç•¥è¨­è¨ˆ â†’ ç³»çµ±ç›£æ§å»ºç«‹ â†’ ç¶­è­·æµç¨‹è¦åŠƒ â†’ ç½é›£æ¢å¾©æº–å‚™ â†’ ä½¿ç”¨è€…æ”¯æ´ â†’ ç”Ÿå‘½é€±æœŸç®¡ç†
      â†“             â†“            â†“           â†“            â†“           â†“
   éƒ¨ç½²è‡ªå‹•åŒ–      æ•ˆèƒ½ç›£æ§      ç‰ˆæœ¬ç¶­è­·    å‚™ä»½æ¢å¾©      æ”¯æ´é«”ç³»     æ°¸çºŒç¶“ç‡Ÿ
```

---

## ğŸš€ ç¬¬ä¸€éƒ¨åˆ†ï¼šéƒ¨ç½²ç­–ç•¥èˆ‡å¯¦å‹™

### 1.1 éƒ¨ç½²åŸºç¤æ¦‚å¿µ

#### ğŸ“ éƒ¨ç½²çš„å®šç¾©èˆ‡é‡è¦æ€§

**è»Ÿé«”éƒ¨ç½² (Software Deployment)** æ˜¯å°‡è»Ÿé«”å¾é–‹ç™¼ç’°å¢ƒé·ç§»åˆ°ç”Ÿç”¢ç’°å¢ƒï¼Œä½¿å…¶èƒ½å¤ ç‚ºä½¿ç”¨è€…æä¾›æœå‹™çš„éç¨‹ã€‚

**éƒ¨ç½²çš„é—œéµè¦ç´ **ï¼š
- **å¯é æ€§**ï¼šéƒ¨ç½²éç¨‹ç©©å®šä¸”å¯é‡è¤‡
- **å¯é æ¸¬æ€§**ï¼šéƒ¨ç½²çµæœå¯é æœŸ
- **å¯å›å¾©æ€§**ï¼šå‡ºå•é¡Œæ™‚èƒ½å¿«é€Ÿå›å¾©
- **å¯è§€æ¸¬æ€§**ï¼šéƒ¨ç½²éç¨‹é€æ˜å¯ç›£æ§

#### ğŸ“Š éƒ¨ç½²å¤±æ•—çš„æˆæœ¬åˆ†æ

**æ¥­ç•Œçµ±è¨ˆé¡¯ç¤º**ï¼š
- æ¯æ¬¡éƒ¨ç½²å¤±æ•—å¹³å‡é€ æˆ **$300,000** æå¤±
- éƒ¨ç½²å•é¡Œå°è‡´çš„åœæ©Ÿæ™‚é–“å¹³å‡ç‚º **4.2å°æ™‚**
- æ‰‹å‹•éƒ¨ç½²çš„éŒ¯èª¤ç‡æ˜¯è‡ªå‹•åŒ–éƒ¨ç½²çš„ **10å€**
- æœ‰æ•ˆçš„éƒ¨ç½²ç­–ç•¥å¯ä»¥æ¸›å°‘ **90%** çš„éƒ¨ç½²ç›¸é—œå•é¡Œ

### 1.2 éƒ¨ç½²ç’°å¢ƒæ¶æ§‹

#### ğŸ—ï¸ å¤šç’°å¢ƒéƒ¨ç½²ç­–ç•¥

**æ¨™æº–ç’°å¢ƒæ¶æ§‹**ï¼š
```
é–‹ç™¼ç’°å¢ƒ (Development)
    â†“
æ¸¬è©¦ç’°å¢ƒ (Testing)
    â†“
é ç”¢ç’°å¢ƒ (Staging)
    â†“
ç”Ÿç”¢ç’°å¢ƒ (Production)
```

**å„ç’°å¢ƒç‰¹æ€§**ï¼š

| ç’°å¢ƒ | ç›®çš„ | æ•¸æ“š | æµé‡ | ç›£æ§ | è‡ªå‹•åŒ–ç¨‹åº¦ |
|------|------|------|------|------|------------|
| **é–‹ç™¼** | åŠŸèƒ½é–‹ç™¼ | æ¨¡æ“¬æ•¸æ“š | é–‹ç™¼è€… | åŸºæœ¬ | é«˜ |
| **æ¸¬è©¦** | åŠŸèƒ½æ¸¬è©¦ | æ¸¬è©¦æ•¸æ“š | QAåœ˜éšŠ | ä¸­ç­‰ | é«˜ |
| **é ç”¢** | ç™¼å¸ƒé©—è­‰ | ç”Ÿç”¢è¤‡æœ¬ | å…§éƒ¨ä½¿ç”¨è€… | å®Œæ•´ | ä¸­ç­‰ |
| **ç”Ÿç”¢** | æ­£å¼æœå‹™ | çœŸå¯¦æ•¸æ“š | æ‰€æœ‰ä½¿ç”¨è€… | å…¨é¢ | ä½ |

#### ğŸ”§ ç’°å¢ƒé…ç½®ç®¡ç†

**Infrastructure as Code (IaC)**ï¼š
```yaml
# docker-compose.yml - é–‹ç™¼ç’°å¢ƒ
version: '3.8'
services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - DB_HOST=db
      - REDIS_URL=redis://redis:6379
    volumes:
      - .:/app
      - /app/node_modules
    depends_on:
      - db
      - redis

  db:
    image: postgres:14
    environment:
      POSTGRES_DB: myapp_dev
      POSTGRES_USER: developer
      POSTGRES_PASSWORD: devpass
    volumes:
      - dev_db_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  dev_db_data:
```

**Kubernetesç”Ÿç”¢ç’°å¢ƒé…ç½®**ï¼š
```yaml
# k8s/production/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-production
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      env: production
  template:
    metadata:
      labels:
        app: myapp
        env: production
    spec:
      containers:
      - name: app
        image: myapp:v1.2.3
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: production
spec:
  selector:
    app: myapp
    env: production
  ports:
  - port: 80
    targetPort: 3000
  type: LoadBalancer
```

### 1.3 éƒ¨ç½²ç­–ç•¥

#### ğŸ”„ è—ç¶ éƒ¨ç½² (Blue-Green Deployment)

**æ¦‚å¿µåœ–**ï¼š
```
Load Balancer
    â”‚
    â”œâ”€ è—ç’°å¢ƒ (v1.0) â† ç›®å‰ç”Ÿç”¢æµé‡
    â”‚
    â””â”€ ç¶ ç’°å¢ƒ (v1.1) â† æ–°ç‰ˆæœ¬å¾…å‘½
    
åˆ‡æ›å¾Œï¼š
Load Balancer
    â”‚
    â”œâ”€ è—ç’°å¢ƒ (v1.0) â† å¾…æ©Ÿç’°å¢ƒ
    â”‚
    â””â”€ ç¶ ç’°å¢ƒ (v1.1) â† æ–°çš„ç”Ÿç”¢æµé‡
```

**å„ªé»**ï¼š
- **é›¶åœæ©Ÿæ™‚é–“**ï¼šç¬é–“åˆ‡æ›
- **å¿«é€Ÿå›å¾©**ï¼šæœ‰å•é¡Œç«‹å³åˆ‡å›
- **å®Œæ•´æ¸¬è©¦**ï¼šæ–°ç‰ˆæœ¬å®Œå…¨é©—è­‰å¾Œæ‰åˆ‡æ›

**å¯¦ä½œç¯„ä¾‹**ï¼š
```bash
#!/bin/bash
# blue-green-deploy.sh

CURRENT_ENV=$(kubectl get service myapp-service -o jsonpath='{.spec.selector.version}')
NEW_ENV=$([ "$CURRENT_ENV" == "blue" ] && echo "green" || echo "blue")

echo "ç›®å‰ç’°å¢ƒ: $CURRENT_ENV"
echo "éƒ¨ç½²åˆ°: $NEW_ENV"

# éƒ¨ç½²æ–°ç‰ˆæœ¬åˆ°å¾…æ©Ÿç’°å¢ƒ
kubectl set image deployment/myapp-$NEW_ENV app=myapp:$1 --namespace=production

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl rollout status deployment/myapp-$NEW_ENV --namespace=production

# åŸ·è¡Œå¥åº·æª¢æŸ¥
if curl -f http://myapp-$NEW_ENV.production.svc.cluster.local/health; then
    echo "å¥åº·æª¢æŸ¥é€šéï¼Œåˆ‡æ›æµé‡"
    
    # åˆ‡æ›ServiceæŒ‡å‘æ–°ç’°å¢ƒ
    kubectl patch service myapp-service -p '{"spec":{"selector":{"version":"'$NEW_ENV'"}}}'
    
    echo "éƒ¨ç½²å®Œæˆï¼æµé‡å·²åˆ‡æ›åˆ° $NEW_ENV ç’°å¢ƒ"
else
    echo "å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œå–æ¶ˆéƒ¨ç½²"
    exit 1
fi
```

#### ğŸ¯ é‡‘çµ²é›€éƒ¨ç½² (Canary Deployment)

**æ¼¸é€²å¼æµé‡åˆ†é…**ï¼š
```
éšæ®µ1: 95%æµé‡ â†’ èˆŠç‰ˆæœ¬, 5%æµé‡ â†’ æ–°ç‰ˆæœ¬
éšæ®µ2: 80%æµé‡ â†’ èˆŠç‰ˆæœ¬, 20%æµé‡ â†’ æ–°ç‰ˆæœ¬
éšæ®µ3: 50%æµé‡ â†’ èˆŠç‰ˆæœ¬, 50%æµé‡ â†’ æ–°ç‰ˆæœ¬
éšæ®µ4: 0%æµé‡ â†’ èˆŠç‰ˆæœ¬, 100%æµé‡ â†’ æ–°ç‰ˆæœ¬
```

**Istioé‡‘çµ²é›€éƒ¨ç½²é…ç½®**ï¼š
```yaml
# istio/canary-deployment.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: myapp-canary
spec:
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: myapp-service
        subset: v2
      weight: 100
  - route:
    - destination:
        host: myapp-service
        subset: v1
      weight: 90
    - destination:
        host: myapp-service
        subset: v2
      weight: 10

---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: myapp-destination
spec:
  host: myapp-service
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
```

#### ğŸŒŠ æ»¾å‹•æ›´æ–° (Rolling Update)

**Kubernetesæ»¾å‹•æ›´æ–°ç­–ç•¥**ï¼š
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-rolling
spec:
  replicas: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1      # æœ€å¤š1å€‹Podä¸å¯ç”¨
      maxSurge: 2           # æœ€å¤šé¡å¤–2å€‹Pod
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1.2.3
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          periodSeconds: 5
          successThreshold: 2
```

**æ»¾å‹•æ›´æ–°è…³æœ¬**ï¼š
```bash
#!/bin/bash
# rolling-update.sh

APP_NAME="myapp"
NEW_IMAGE="myapp:$1"
NAMESPACE="production"

echo "é–‹å§‹æ»¾å‹•æ›´æ–°åˆ° $NEW_IMAGE"

# æ›´æ–°é¡åƒ
kubectl set image deployment/$APP_NAME app=$NEW_IMAGE -n $NAMESPACE

# ç›£æ§æ›´æ–°éç¨‹
kubectl rollout status deployment/$APP_NAME -n $NAMESPACE --timeout=600s

if [ $? -eq 0 ]; then
    echo "æ»¾å‹•æ›´æ–°æˆåŠŸå®Œæˆ"
    
    # é©—è­‰æ›´æ–°
    kubectl get pods -l app=$APP_NAME -n $NAMESPACE
    
    # æª¢æŸ¥å¥åº·ç‹€æ…‹
    for i in {1..5}; do
        if curl -f http://$APP_NAME.$NAMESPACE.svc.cluster.local/health; then
            echo "å¥åº·æª¢æŸ¥é€šé"
            break
        else
            echo "ç­‰å¾…æœå‹™å°±ç·’... ($i/5)"
            sleep 10
        fi
    done
else
    echo "æ»¾å‹•æ›´æ–°å¤±æ•—ï¼ŒåŸ·è¡Œå›å¾©"
    kubectl rollout undo deployment/$APP_NAME -n $NAMESPACE
    exit 1
fi
```

### 1.4 è‡ªå‹•åŒ–éƒ¨ç½²æµç¨‹

#### ğŸ¤– CI/CD Pipelineè¨­è¨ˆ

**å®Œæ•´éƒ¨ç½²æµç¨‹**ï¼š
```yaml
# .github/workflows/deploy.yml
name: Production Deployment

on:
  push:
    tags:
      - 'v*'

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.image.outputs.image }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v3
    
    - name: è¨­å®šDocker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: ç™»å…¥Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: æå–metadata
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=tag
          type=sha
    
    - name: å»ºç½®ä¸¦æ¨é€Dockeræ˜ åƒ
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: è¼¸å‡ºæ˜ åƒåç¨±
      id: image
      run: echo "image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}" >> $GITHUB_OUTPUT

  security-scan:
    needs: build
    runs-on: ubuntu-latest
    
    steps:
    - name: å®‰å…¨æƒæ
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ needs.build.outputs.image }}
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: ä¸Šå‚³æƒæçµæœ
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  deploy-staging:
    needs: [build, security-scan]
    runs-on: ubuntu-latest
    environment: staging
    
    steps:
    - name: éƒ¨ç½²åˆ°Staging
      run: |
        echo "éƒ¨ç½² ${{ needs.build.outputs.image }} åˆ°stagingç’°å¢ƒ"
        # å¯¦éš›éƒ¨ç½²å‘½ä»¤
        kubectl set image deployment/myapp-staging app=${{ needs.build.outputs.image }}
        kubectl rollout status deployment/myapp-staging
    
    - name: åŸ·è¡Œç…™éœ§æ¸¬è©¦
      run: |
        # åŸ·è¡ŒåŸºæœ¬åŠŸèƒ½æ¸¬è©¦
        npm run test:smoke -- --env=staging

  deploy-production:
    needs: [build, deploy-staging]
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: å‰µå»ºéƒ¨ç½²issue
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `ç”Ÿç”¢éƒ¨ç½²: ${{ github.ref_name }}`,
            body: `
              ## éƒ¨ç½²è³‡è¨Š
              - **ç‰ˆæœ¬**: ${{ github.ref_name }}
              - **æ˜ åƒ**: ${{ needs.build.outputs.image }}
              - **è§¸ç™¼è€…**: ${{ github.actor }}
              
              ## æª¢æŸ¥æ¸…å–®
              - [ ] ç¢ºèªstagingæ¸¬è©¦é€šé
              - [ ] ç¢ºèªè³‡æ–™åº«é·ç§»è¨ˆç•«
              - [ ] ç¢ºèªå›å¾©è¨ˆç•«
              - [ ] é€šçŸ¥ç›¸é—œåœ˜éšŠ
            `
          })
    
    - name: è—ç¶ éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ
      run: |
        echo "é–‹å§‹è—ç¶ éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ"
        ./scripts/blue-green-deploy.sh ${{ needs.build.outputs.image }}
    
    - name: åŸ·è¡Œç”Ÿç”¢ç’°å¢ƒæ¸¬è©¦
      run: |
        npm run test:production
    
    - name: ç™¼é€éƒ¨ç½²é€šçŸ¥
      uses: 8398a7/action-slack@v3
      with:
        status: success
        text: |
          ğŸš€ ç”Ÿç”¢éƒ¨ç½²æˆåŠŸï¼
          ç‰ˆæœ¬: ${{ github.ref_name }}
          éƒ¨ç½²è€…: ${{ github.actor }}
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

---

## ğŸ“Š ç¬¬äºŒéƒ¨åˆ†ï¼šç³»çµ±ç›£æ§èˆ‡æ•ˆèƒ½ç®¡ç†

### 2.1 ç›£æ§ç­–ç•¥è¨­è¨ˆ

#### ğŸ¯ ç›£æ§çš„å››å€‹é»ƒé‡‘æŒ‡æ¨™

**SREé»ƒé‡‘æŒ‡æ¨™**ï¼š
1. **å»¶é² (Latency)**ï¼šè«‹æ±‚å›æ‡‰æ™‚é–“
2. **æµé‡ (Traffic)**ï¼šç³»çµ±è™•ç†çš„è«‹æ±‚é‡
3. **éŒ¯èª¤ç‡ (Errors)**ï¼šå¤±æ•—è«‹æ±‚çš„æ¯”ä¾‹
4. **é£½å’Œåº¦ (Saturation)**ï¼šç³»çµ±è³‡æºä½¿ç”¨ç¨‹åº¦

#### ğŸ“ˆ ç›£æ§å±¤ç´šæ¶æ§‹

```
æ¥­å‹™ç›£æ§ (Business Metrics)
    â†“
æ‡‰ç”¨ç›£æ§ (Application Metrics)  
    â†“
åŸºç¤è¨­æ–½ç›£æ§ (Infrastructure Metrics)
    â†“
ç¶²è·¯ç›£æ§ (Network Metrics)
```

**å„å±¤ç´šç›£æ§é‡é»**ï¼š

| å±¤ç´š | ç›£æ§å…§å®¹ | å·¥å…· | å‘Šè­¦é–¾å€¼ |
|------|----------|------|----------|
| **æ¥­å‹™** | è¨»å†Šæ•¸ã€äº¤æ˜“é¡ã€è½‰æ›ç‡ | Google Analytics, Mixpanel | æ¥­å‹™KPI |
| **æ‡‰ç”¨** | å›æ‡‰æ™‚é–“ã€éŒ¯èª¤ç‡ã€ååé‡ | Prometheus, New Relic | 99%å¯ç”¨æ€§ |
| **åŸºç¤è¨­æ–½** | CPUã€è¨˜æ†¶é«”ã€ç£ç¢Ÿã€ç¶²è·¯ | Grafana, DataDog | 80%ä½¿ç”¨ç‡ |
| **ç¶²è·¯** | é »å¯¬ã€å»¶é²ã€å°åŒ…éºå¤± | Nagios, Zabbix | ç¶²è·¯å“è³ª |

### 2.2 Prometheusç›£æ§å¯¦ä½œ

#### ğŸ”§ Prometheusé…ç½®

**prometheus.ymlé…ç½®**ï¼š
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'myapp'
    static_configs:
      - targets: ['myapp:3000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
```

#### ğŸ“Š æ‡‰ç”¨ç¨‹å¼æŒ‡æ¨™å¯¦ä½œ

**Node.jsæ‡‰ç”¨ç¨‹å¼æŒ‡æ¨™**ï¼š
```javascript
// metrics.js
const prometheus = require('prom-client');

// å»ºç«‹æŒ‡æ¨™æ”¶é›†å™¨
const collectDefaultMetrics = prometheus.collectDefaultMetrics;
collectDefaultMetrics({ timeout: 5000 });

// è‡ªå®šç¾©æ¥­å‹™æŒ‡æ¨™
const httpRequestsTotal = new prometheus.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status_code']
});

const httpRequestDuration = new prometheus.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]
});

const activeUsers = new prometheus.Gauge({
  name: 'active_users_total',
  help: 'Total number of active users'
});

const databaseConnections = new prometheus.Gauge({
  name: 'database_connections_active',
  help: 'Number of active database connections'
});

// ä¸­é–“ä»¶å‡½æ•¸
function metricsMiddleware(req, res, next) {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    const route = req.route ? req.route.path : req.path;
    
    httpRequestsTotal
      .labels(req.method, route, res.statusCode)
      .inc();
    
    httpRequestDuration
      .labels(req.method, route, res.statusCode)
      .observe(duration);
  });
  
  next();
}

// æ¥­å‹™æŒ‡æ¨™æ›´æ–°å‡½æ•¸
function updateBusinessMetrics() {
  setInterval(async () => {
    try {
      // æ›´æ–°æ´»èºä½¿ç”¨è€…æ•¸
      const activeUserCount = await getActiveUserCount();
      activeUsers.set(activeUserCount);
      
      // æ›´æ–°è³‡æ–™åº«é€£æ¥æ•¸
      const dbConnections = await getDatabaseConnectionCount();
      databaseConnections.set(dbConnections);
      
    } catch (error) {
      console.error('æ›´æ–°æ¥­å‹™æŒ‡æ¨™å¤±æ•—:', error);
    }
  }, 30000); // æ¯30ç§’æ›´æ–°ä¸€æ¬¡
}

module.exports = {
  prometheus,
  metricsMiddleware,
  updateBusinessMetrics,
  register: prometheus.register
};

// app.js
const express = require('express');
const { metricsMiddleware, register, updateBusinessMetrics } = require('./metrics');

const app = express();

// ä½¿ç”¨æŒ‡æ¨™ä¸­é–“ä»¶
app.use(metricsMiddleware);

// æŒ‡æ¨™ç«¯é»
app.get('/metrics', (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(register.metrics());
});

// å¥åº·æª¢æŸ¥ç«¯é»
app.get('/health', (req, res) => {
  res.json({ status: 'healthy', timestamp: new Date().toISOString() });
});

// å•Ÿå‹•æ¥­å‹™æŒ‡æ¨™æ›´æ–°
updateBusinessMetrics();

app.listen(3000, () => {
  console.log('æ‡‰ç”¨ç¨‹å¼é‹è¡Œåœ¨ http://localhost:3000');
});
```

### 2.3 å‘Šè­¦ç³»çµ±è¨­è¨ˆ

#### ğŸš¨ å‘Šè­¦è¦å‰‡é…ç½®

**alert_rules.yml**ï¼š
```yaml
groups:
- name: application.rules
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status_code=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "é«˜éŒ¯èª¤ç‡åµæ¸¬"
      description: "æ‡‰ç”¨ç¨‹å¼éŒ¯èª¤ç‡è¶…é10%ï¼ŒæŒçºŒ5åˆ†é˜"

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "å›æ‡‰æ™‚é–“éé•·"
      description: "95%å›æ‡‰æ™‚é–“è¶…é1ç§’ï¼ŒæŒçºŒ3åˆ†é˜"

  - alert: DatabaseConnectionHigh
    expr: database_connections_active > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "è³‡æ–™åº«é€£æ¥æ•¸éé«˜"
      description: "è³‡æ–™åº«é€£æ¥æ•¸è¶…é80ï¼Œç›®å‰: {{ $value }}"

- name: infrastructure.rules
  rules:
  - alert: HighCPUUsage
    expr: 100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "CPUä½¿ç”¨ç‡éé«˜"
      description: "CPUä½¿ç”¨ç‡è¶…é85%ï¼ŒæŒçºŒ5åˆ†é˜"

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
    for: 3m
    labels:
      severity: critical
    annotations:
      summary: "è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜"
      description: "è¨˜æ†¶é«”ä½¿ç”¨ç‡è¶…é90%ï¼ŒæŒçºŒ3åˆ†é˜"

  - alert: DiskSpaceLow
    expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "ç£ç¢Ÿç©ºé–“ä¸è¶³"
      description: "ç£ç¢Ÿä½¿ç”¨ç‡è¶…é85%ï¼Œå‰©ä½™ç©ºé–“: {{ $value }}%"
```

#### ğŸ“± Alertmanageré€šçŸ¥é…ç½®

**alertmanager.yml**ï¼š
```yaml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@mycompany.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
    group_wait: 0s
    repeat_interval: 5m
  - match:
      severity: warning
    receiver: 'warning-alerts'

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://webhook-server:5000/webhook'

- name: 'critical-alerts'
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#critical-alerts'
    title: 'ğŸš¨ åš´é‡å‘Šè­¦'
    text: |
      {{ range .Alerts }}
      å‘Šè­¦: {{ .Annotations.summary }}
      æè¿°: {{ .Annotations.description }}
      æ™‚é–“: {{ .StartsAt }}
      {{ end }}
  email_configs:
  - to: 'oncall@mycompany.com'
    subject: 'ã€ç·Šæ€¥ã€‘ç”Ÿç”¢ç’°å¢ƒå‘Šè­¦'
    body: |
      {{ range .Alerts }}
      å‘Šè­¦åç¨±: {{ .Annotations.summary }}
      è©³ç´°æè¿°: {{ .Annotations.description }}
      å‘Šè­¦æ™‚é–“: {{ .StartsAt }}
      {{ end }}

- name: 'warning-alerts'
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#monitoring'
    title: 'âš ï¸ è­¦å‘Šå‘Šè­¦'
    text: |
      {{ range .Alerts }}
      å‘Šè­¦: {{ .Annotations.summary }}
      æè¿°: {{ .Annotations.description }}
      {{ end }}
```

### 2.4 æ•ˆèƒ½èª¿æ ¡

#### âš¡ æ‡‰ç”¨ç¨‹å¼æ•ˆèƒ½å„ªåŒ–

**Node.jsæ•ˆèƒ½å„ªåŒ–æŠ€å·§**ï¼š
```javascript
// performance-optimizations.js

// 1. é€£æ¥æ± å„ªåŒ–
const { Pool } = require('pg');
const pool = new Pool({
  host: 'localhost',
  user: 'dbuser',
  password: 'secretpassword',
  database: 'mydb',
  max: 20,                // æœ€å¤§é€£æ¥æ•¸
  idleTimeoutMillis: 30000, // é–’ç½®è¶…æ™‚
  connectionTimeoutMillis: 2000, // é€£æ¥è¶…æ™‚
});

// 2. å¿«å–ç­–ç•¥
const Redis = require('redis');
const redis = Redis.createClient({
  host: 'redis-server',
  port: 6379,
  retry_strategy: (options) => {
    if (options.error && options.error.code === 'ECONNREFUSED') {
      return new Error('Redisæœå‹™å™¨æ‹’çµ•é€£æ¥');
    }
    if (options.total_retry_time > 1000 * 60 * 60) {
      return new Error('é‡è©¦æ™‚é–“è¶…é1å°æ™‚');
    }
    if (options.attempt > 10) {
      return undefined;
    }
    return Math.min(options.attempt * 100, 3000);
  }
});

// å¿«å–ä¸­é–“ä»¶
function cacheMiddleware(duration = 300) {
  return async (req, res, next) => {
    const key = req.originalUrl;
    
    try {
      const cached = await redis.get(key);
      if (cached) {
        return res.json(JSON.parse(cached));
      }
      
      // è¦†å¯«res.jsonä»¥å¿«å–çµæœ
      const originalJson = res.json;
      res.json = function(data) {
        redis.setex(key, duration, JSON.stringify(data));
        return originalJson.call(this, data);
      };
      
      next();
    } catch (error) {
      console.error('å¿«å–éŒ¯èª¤:', error);
      next();
    }
  };
}

// 3. è³‡æ–™åº«æŸ¥è©¢å„ªåŒ–
class UserService {
  // æ‰¹æ¬¡æŸ¥è©¢å„ªåŒ–
  async getUsersWithPosts(userIds) {
    // âŒ N+1æŸ¥è©¢å•é¡Œ
    // const users = await User.findAll({ where: { id: userIds } });
    // for (const user of users) {
    //   user.posts = await Post.findAll({ where: { userId: user.id } });
    // }
    
    // âœ… å„ªåŒ–çš„æŸ¥è©¢
    const users = await User.findAll({
      where: { id: userIds },
      include: [{
        model: Post,
        required: false
      }]
    });
    
    return users;
  }
  
  // åˆ†é æŸ¥è©¢å„ªåŒ–
  async getUsersPaginated(page, limit) {
    const offset = (page - 1) * limit;
    
    // ä½¿ç”¨å­æŸ¥è©¢å„ªåŒ–å¤§è¡¨åˆ†é 
    const { count, rows } = await User.findAndCountAll({
      attributes: ['id', 'name', 'email'],
      order: [['created_at', 'DESC']],
      limit,
      offset,
      distinct: true
    });
    
    return {
      users: rows,
      totalPages: Math.ceil(count / limit),
      currentPage: page,
      total: count
    };
  }
}

// 4. å£“ç¸®å’Œéœæ…‹è³‡æºå„ªåŒ–
const compression = require('compression');
const express = require('express');
const app = express();

// å•Ÿç”¨GZIPå£“ç¸®
app.use(compression({
  filter: (req, res) => {
    if (req.headers['x-no-compression']) {
      return false;
    }
    return compression.filter(req, res);
  },
  level: 6,
  threshold: 1024
}));

// éœæ…‹è³‡æºå¿«å–
app.use('/static', express.static('public', {
  maxAge: '1d',
  etag: true,
  lastModified: true
}));

// 5. è«‹æ±‚é™åˆ¶å’Œé˜²æ¿«ç”¨
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15åˆ†é˜
  max: 100, // é™åˆ¶æ¯å€‹IPæœ€å¤š100å€‹è«‹æ±‚
  message: {
    error: 'è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦',
    retryAfter: 15 * 60
  },
  standardHeaders: true,
  legacyHeaders: false
});

app.use('/api', limiter);

module.exports = {
  pool,
  redis,
  cacheMiddleware,
  UserService
};
```

#### ğŸ—„ï¸ è³‡æ–™åº«æ•ˆèƒ½å„ªåŒ–

**PostgreSQLå„ªåŒ–é…ç½®**ï¼š
```sql
-- postgresql.confå„ªåŒ–è¨­å®š

-- è¨˜æ†¶é«”è¨­å®š
shared_buffers = 256MB              -- å…±äº«ç·©è¡å€
effective_cache_size = 1GB          -- æœ‰æ•ˆå¿«å–å¤§å°
work_mem = 4MB                      -- å·¥ä½œè¨˜æ†¶é«”
maintenance_work_mem = 64MB         -- ç¶­è­·å·¥ä½œè¨˜æ†¶é«”

-- é€£æ¥è¨­å®š
max_connections = 100               -- æœ€å¤§é€£æ¥æ•¸
shared_preload_libraries = 'pg_stat_statements'

-- æŸ¥è©¢å„ªåŒ–
random_page_cost = 1.1              -- éš¨æ©Ÿé é¢æˆæœ¬
effective_io_concurrency = 200      -- æœ‰æ•ˆIOä¸¦ç™¼

-- æ—¥èªŒè¨­å®š
log_statement = 'all'               -- è¨˜éŒ„æ‰€æœ‰èªå¥
log_min_duration_statement = 1000   -- è¨˜éŒ„åŸ·è¡Œè¶…é1ç§’çš„æŸ¥è©¢
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
```

**æŸ¥è©¢å„ªåŒ–ç¯„ä¾‹**ï¼š
```sql
-- 1. ç´¢å¼•å„ªåŒ–
-- æŸ¥è©¢åŸ·è¡Œè¨ˆç•«åˆ†æ
EXPLAIN (ANALYZE, BUFFERS) 
SELECT u.name, p.title 
FROM users u 
JOIN posts p ON u.id = p.user_id 
WHERE u.created_at > '2024-01-01';

-- å»ºç«‹è¤‡åˆç´¢å¼•
CREATE INDEX CONCURRENTLY idx_users_created_at_id 
ON users(created_at, id);

CREATE INDEX CONCURRENTLY idx_posts_user_id_title 
ON posts(user_id, title);

-- 2. åˆ†å€è¡¨å„ªåŒ–
-- æŒ‰æ™‚é–“åˆ†å€çš„æ—¥èªŒè¡¨
CREATE TABLE access_logs (
    id BIGSERIAL,
    user_id INTEGER,
    endpoint VARCHAR(255),
    response_time INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

-- å»ºç«‹åˆ†å€
CREATE TABLE access_logs_2024_q1 
PARTITION OF access_logs 
FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');

CREATE TABLE access_logs_2024_q2 
PARTITION OF access_logs 
FOR VALUES FROM ('2024-04-01') TO ('2024-07-01');

-- 3. æŸ¥è©¢å„ªåŒ–æŠ€å·§
-- ä½¿ç”¨EXISTSä»£æ›¿IN (å­æŸ¥è©¢)
-- âŒ æ•ˆèƒ½è¼ƒå·®
SELECT * FROM users 
WHERE id IN (SELECT user_id FROM posts WHERE status = 'published');

-- âœ… æ•ˆèƒ½è¼ƒå¥½
SELECT * FROM users u
WHERE EXISTS (
    SELECT 1 FROM posts p 
    WHERE p.user_id = u.id AND p.status = 'published'
);

-- 4. æ‰¹æ¬¡æ“ä½œå„ªåŒ–
-- æ‰¹æ¬¡æ’å…¥
INSERT INTO users (name, email, created_at)
SELECT 
    'User ' || generate_series(1, 1000),
    'user' || generate_series(1, 1000) || '@example.com',
    CURRENT_TIMESTAMP
ON CONFLICT (email) DO NOTHING;

-- æ‰¹æ¬¡æ›´æ–°
UPDATE posts 
SET view_count = view_count + views.increment
FROM (VALUES 
    (1, 10),
    (2, 15),
    (3, 5)
) AS views(post_id, increment)
WHERE posts.id = views.post_id;
```

---

## ğŸ”§ ç¬¬ä¸‰éƒ¨åˆ†ï¼šç¶­è­·ç®¡ç†

### 3.1 ç¶­è­·ç­–ç•¥è¦åŠƒ

#### ğŸ“‹ è»Ÿé«”ç¶­è­·é¡å‹

**IEEEæ¨™æº–ç¶­è­·åˆ†é¡**ï¼š

1. **ä¿®æ­£æ€§ç¶­è­· (Corrective Maintenance)**
   - **ç›®çš„**ï¼šä¿®å¾©å·²ç™¼ç¾çš„éŒ¯èª¤å’Œç¼ºé™·
   - **æ¯”ä¾‹**ï¼šç´„20%çš„ç¶­è­·å·¥ä½œ
   - **å„ªå…ˆç´š**ï¼šæœ€é«˜

2. **é©æ‡‰æ€§ç¶­è­· (Adaptive Maintenance)**
   - **ç›®çš„**ï¼šé©æ‡‰ç’°å¢ƒè®ŠåŒ–ï¼ˆOSã€ç¡¬é«”ã€æ³•è¦ï¼‰
   - **æ¯”ä¾‹**ï¼šç´„25%çš„ç¶­è­·å·¥ä½œ
   - **ç‰¹é»**ï¼šé é˜²æ€§

3. **å®Œå–„æ€§ç¶­è­· (Perfective Maintenance)**
   - **ç›®çš„**ï¼šæ”¹å–„åŠŸèƒ½å’Œæ•ˆèƒ½
   - **æ¯”ä¾‹**ï¼šç´„50%çš„ç¶­è­·å·¥ä½œ
   - **é©…å‹•**ï¼šä½¿ç”¨è€…éœ€æ±‚

4. **é é˜²æ€§ç¶­è­· (Preventive Maintenance)**
   - **ç›®çš„**ï¼šé é˜²æœªä¾†å•é¡Œ
   - **æ¯”ä¾‹**ï¼šç´„5%çš„ç¶­è­·å·¥ä½œ
   - **åƒ¹å€¼**ï¼šé•·æœŸç©©å®š

#### ğŸ“Š ç¶­è­·æˆæœ¬åˆ†æ

**ç¶­è­·æˆæœ¬åˆ†ä½ˆ**ï¼š
```
è»Ÿé«”ç”Ÿå‘½é€±æœŸç¸½æˆæœ¬
â”œâ”€â”€ é–‹ç™¼æˆæœ¬ (30%)
â”‚   â”œâ”€â”€ éœ€æ±‚åˆ†æ (5%)
â”‚   â”œâ”€â”€ è¨­è¨ˆ (8%)
â”‚   â”œâ”€â”€ ç·¨ç¢¼ (12%)
â”‚   â””â”€â”€ æ¸¬è©¦ (5%)
â””â”€â”€ ç¶­è­·æˆæœ¬ (70%)
    â”œâ”€â”€ ä¿®æ­£æ€§ç¶­è­· (14%)
    â”œâ”€â”€ é©æ‡‰æ€§ç¶­è­· (18%)
    â”œâ”€â”€ å®Œå–„æ€§ç¶­è­· (35%)
    â””â”€â”€ é é˜²æ€§ç¶­è­· (3%)
```

### 3.2 ç‰ˆæœ¬ç®¡ç†ç­–ç•¥

#### ğŸ·ï¸ èªæ„åŒ–ç‰ˆæœ¬æ§åˆ¶å¯¦å‹™

**ç‰ˆæœ¬è™Ÿæ ¼å¼ï¼šMAJOR.MINOR.PATCH**

```javascript
// version-manager.js
class VersionManager {
  constructor(currentVersion = '1.0.0') {
    this.version = this.parseVersion(currentVersion);
  }
  
  parseVersion(versionString) {
    const [major, minor, patch] = versionString.split('.').map(Number);
    return { major, minor, patch };
  }
  
  // ä¸»ç‰ˆæœ¬è™Ÿï¼šä¸ç›¸å®¹çš„APIè®Šæ›´
  incrementMajor() {
    this.version.major += 1;
    this.version.minor = 0;
    this.version.patch = 0;
    return this.toString();
  }
  
  // æ¬¡ç‰ˆæœ¬è™Ÿï¼šå‘å¾Œç›¸å®¹çš„æ–°åŠŸèƒ½
  incrementMinor() {
    this.version.minor += 1;
    this.version.patch = 0;
    return this.toString();
  }
  
  // ä¿®è¨‚ç‰ˆæœ¬è™Ÿï¼šå‘å¾Œç›¸å®¹çš„éŒ¯èª¤ä¿®å¾©
  incrementPatch() {
    this.version.patch += 1;
    return this.toString();
  }
  
  toString() {
    return `${this.version.major}.${this.version.minor}.${this.version.patch}`;
  }
  
  // é ç™¼å¸ƒç‰ˆæœ¬
  createPrerelease(type = 'alpha', number = 1) {
    return `${this.toString()}-${type}.${number}`;
  }
}

// ä½¿ç”¨ç¯„ä¾‹
const vm = new VersionManager('2.1.3');
console.log(vm.incrementPatch()); // 2.1.4
console.log(vm.incrementMinor()); // 2.2.0
console.log(vm.createPrerelease('beta', 2)); // 2.2.0-beta.2
```

#### ğŸ”„ ç™¼å¸ƒç®¡ç†æµç¨‹

**è‡ªå‹•åŒ–ç‰ˆæœ¬ç™¼å¸ƒè…³æœ¬**ï¼š
```bash
#!/bin/bash
# release.sh

set -e

# åƒæ•¸é©—è­‰
if [ $# -eq 0 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <patch|minor|major>"
    exit 1
fi

RELEASE_TYPE=$1
CURRENT_BRANCH=$(git branch --show-current)

# ç¢ºä¿åœ¨mainåˆ†æ”¯
if [ "$CURRENT_BRANCH" != "main" ]; then
    echo "éŒ¯èª¤ï¼šå¿…é ˆåœ¨mainåˆ†æ”¯ä¸ŠåŸ·è¡Œç™¼å¸ƒ"
    exit 1
fi

# ç¢ºä¿å·¥ä½œç›®éŒ„ä¹¾æ·¨
if [ -n "$(git status --porcelain)" ]; then
    echo "éŒ¯èª¤ï¼šå·¥ä½œç›®éŒ„æœ‰æœªæäº¤çš„è®Šæ›´"
    exit 1
fi

# æ‹‰å–æœ€æ–°ä»£ç¢¼
git pull origin main

# åŸ·è¡Œæ¸¬è©¦
echo "åŸ·è¡Œæ¸¬è©¦å¥—ä»¶..."
npm test
if [ $? -ne 0 ]; then
    echo "éŒ¯èª¤ï¼šæ¸¬è©¦å¤±æ•—"
    exit 1
fi

# æ›´æ–°ç‰ˆæœ¬è™Ÿ
echo "æ›´æ–°ç‰ˆæœ¬è™Ÿ..."
NEW_VERSION=$(npm version $RELEASE_TYPE --no-git-tag-version)
echo "æ–°ç‰ˆæœ¬: $NEW_VERSION"

# æ›´æ–°CHANGELOG
echo "æ›´æ–°CHANGELOG..."
npx auto-changelog

# æäº¤ç‰ˆæœ¬è®Šæ›´
git add package.json package-lock.json CHANGELOG.md
git commit -m "chore: release $NEW_VERSION"

# å»ºç«‹æ¨™ç±¤
git tag -a $NEW_VERSION -m "Release $NEW_VERSION"

# æ¨é€åˆ°é ç¨‹å€‰åº«
git push origin main
git push origin $NEW_VERSION

echo "ç™¼å¸ƒ $NEW_VERSION å®Œæˆï¼"

# è§¸ç™¼CI/CDéƒ¨ç½²
echo "è§¸ç™¼è‡ªå‹•éƒ¨ç½²..."
gh workflow run deploy.yml --ref $NEW_VERSION
```

### 3.3 è®Šæ›´ç®¡ç†

#### ğŸ“ è®Šæ›´æ§åˆ¶æµç¨‹

**RFC (Request for Comments) æµç¨‹**ï¼š
```markdown
# RFC-001: è³‡æ–™åº«åˆ†ç‰‡æ¶æ§‹æ”¹é€ 

## æ‘˜è¦
ç‚ºäº†æ”¯æ’å¿«é€Ÿå¢é•·çš„ä½¿ç”¨è€…é‡ï¼Œæè­°å°‡ç¾æœ‰å–®é«”è³‡æ–™åº«æ”¹é€ ç‚ºåˆ†ç‰‡æ¶æ§‹ã€‚

## å‹•æ©Ÿ
- ç›®å‰è³‡æ–™åº«QPSå·²é”åˆ°70%ä¸Šé™
- è³‡æ–™é‡é è¨ˆåœ¨6å€‹æœˆå…§å¢é•·3å€
- å–®é»æ•…éšœé¢¨éšªéé«˜

## è©³ç´°è¨­è¨ˆ
### åˆ†ç‰‡ç­–ç•¥
- æŒ‰ç”¨æˆ¶IDé€²è¡Œæ°´å¹³åˆ†ç‰‡
- ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œç®—æ³•
- åˆæœŸå»ºç«‹4å€‹åˆ†ç‰‡

### é·ç§»è¨ˆç•«
1. å»ºç«‹æ–°çš„åˆ†ç‰‡è³‡æ–™åº«
2. å¯¦ä½œåˆ†ç‰‡è·¯ç”±å±¤
3. é›™å¯«æ¨¡å¼é©—è­‰
4. é€æ­¥é·ç§»æ­·å²è³‡æ–™
5. åˆ‡æ›è®€å¯«æµé‡

## é¢¨éšªèˆ‡ç·©è§£
| é¢¨éšª | æ©Ÿç‡ | å½±éŸ¿ | ç·©è§£ç­–ç•¥ |
|------|------|------|----------|
| è³‡æ–™ä¸ä¸€è‡´ | ä¸­ | é«˜ | é›™å¯«é©—è­‰ + è³‡æ–™å°æ¯” |
| æ•ˆèƒ½ä¸‹é™ | ä½ | ä¸­ | å……åˆ†æ¸¬è©¦ + å›å¾©è¨ˆç•« |
| åœæ©Ÿæ™‚é–“ | ä¸­ | é«˜ | åˆ†éšæ®µé·ç§» |

## æ™‚ç¨‹è¦åŠƒ
- ç¬¬1é€±ï¼šåˆ†ç‰‡è¨­è¨ˆ + è·¯ç”±å±¤é–‹ç™¼
- ç¬¬2é€±ï¼šæ¸¬è©¦ç’°å¢ƒé©—è­‰
- ç¬¬3é€±ï¼šé›™å¯«æ¨¡å¼ä¸Šç·š
- ç¬¬4é€±ï¼šè³‡æ–™é·ç§»
- ç¬¬5é€±ï¼šæµé‡åˆ‡æ›

## æˆåŠŸæ¨™æº–
- è³‡æ–™åº«QPSå®¹é‡æå‡3å€
- P99å»¶é²ç¶­æŒåœ¨100msä»¥ä¸‹
- é›¶è³‡æ–™éºå¤±
- åœæ©Ÿæ™‚é–“å°‘æ–¼1å°æ™‚
```

#### ğŸ”„ ç·Šæ€¥è®Šæ›´æµç¨‹

**ç”Ÿç”¢ç’°å¢ƒç·Šæ€¥ä¿®å¾©æµç¨‹**ï¼š
```bash
#!/bin/bash
# hotfix.sh

ISSUE_ID=$1
DESCRIPTION=$2

if [ -z "$ISSUE_ID" ] || [ -z "$DESCRIPTION" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <ISSUE_ID> <DESCRIPTION>"
    echo "ç¯„ä¾‹: $0 CRITICAL-123 'ä¿®å¾©æ”¯ä»˜APIç•°å¸¸'"
    exit 1
fi

echo "ğŸš¨ é–‹å§‹ç·Šæ€¥ä¿®å¾©æµç¨‹"
echo "å•é¡ŒID: $ISSUE_ID"
echo "æè¿°: $DESCRIPTION"

# 1. å¾ç”Ÿç”¢åˆ†æ”¯å»ºç«‹hotfixåˆ†æ”¯
git checkout main
git pull origin main
HOTFIX_BRANCH="hotfix/$ISSUE_ID"
git checkout -b $HOTFIX_BRANCH

echo "âœ… å»ºç«‹hotfixåˆ†æ”¯: $HOTFIX_BRANCH"

# 2. æé†’é–‹ç™¼è€…é€²è¡Œä¿®å¾©
echo "ğŸ“ è«‹é€²è¡Œå¿…è¦çš„ç¨‹å¼ç¢¼ä¿®å¾©..."
echo "å®Œæˆå¾ŒæŒ‰Enterç¹¼çºŒï¼Œæˆ–Ctrl+Cå–æ¶ˆ"
read

# 3. é©—è­‰ä¿®å¾©
echo "ğŸ§ª åŸ·è¡Œå¿«é€Ÿæ¸¬è©¦..."
npm run test:critical
if [ $? -ne 0 ]; then
    echo "âŒ é—œéµæ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¿®å¾©"
    exit 1
fi

# 4. æäº¤ä¿®å¾©
git add .
git commit -m "fix: $DESCRIPTION ($ISSUE_ID)"
git push origin $HOTFIX_BRANCH

# 5. å»ºç«‹ç·Šæ€¥PR
gh pr create \
    --title "ğŸš¨ HOTFIX: $DESCRIPTION" \
    --body "## ç·Šæ€¥ä¿®å¾©

**å•é¡ŒID**: $ISSUE_ID
**æè¿°**: $DESCRIPTION

### ä¿®å¾©å…§å®¹
- [ ] å•é¡ŒåŸå› åˆ†æ
- [ ] ä¿®å¾©æ–¹æ¡ˆå¯¦æ–½
- [ ] æ¸¬è©¦é©—è­‰å®Œæˆ

### éƒ¨ç½²æª¢æŸ¥æ¸…å–®
- [ ] ç¨‹å¼ç¢¼å¯©æŸ¥ (ç°¡åŒ–æµç¨‹)
- [ ] ç·Šæ€¥æ¸¬è©¦é€šé
- [ ] éƒ¨ç½²è¨ˆç•«ç¢ºèª
- [ ] å›å¾©è¨ˆç•«æº–å‚™

âš ï¸ æ­¤ç‚ºç·Šæ€¥ä¿®å¾©ï¼Œè«‹å„ªå…ˆè™•ç†" \
    --assignee "@me" \
    --label "hotfix,critical"

echo "ğŸ¯ ç·Šæ€¥PRå·²å»ºç«‹ï¼Œè«‹ç›¡å¿«é€²è¡Œå¯©æŸ¥å’Œéƒ¨ç½²"

# 6. é€šçŸ¥ç›¸é—œåœ˜éšŠ
curl -X POST -H 'Content-type: application/json' \
    --data "{\"text\":\"ğŸš¨ ç·Šæ€¥ä¿®å¾©PRå·²å»ºç«‹\nå•é¡Œ: $DESCRIPTION\nPR: $(gh pr view --json url -q .url)\"}" \
    $SLACK_WEBHOOK_URL

echo "ğŸ“¢ å·²é€šçŸ¥ç›¸é—œåœ˜éšŠ"
```

### 3.4 æŠ€è¡“å‚µå‹™ç®¡ç†

#### ğŸ“Š æŠ€è¡“å‚µå‹™è©•ä¼°

**æŠ€è¡“å‚µå‹™è©•ä¼°çŸ©é™£**ï¼š
```javascript
// technical-debt-analyzer.js
class TechnicalDebtAnalyzer {
  constructor() {
    this.metrics = {
      codeComplexity: 0,
      testCoverage: 0,
      duplication: 0,
      dependencies: 0,
      documentation: 0
    };
  }
  
  // ç¨‹å¼ç¢¼è¤‡é›œåº¦åˆ†æ
  analyzeComplexity(filePath) {
    // ä½¿ç”¨ESLintè¤‡é›œåº¦è¦å‰‡
    const complexity = this.calculateCyclomaticComplexity(filePath);
    
    return {
      score: this.normalizeScore(complexity, 1, 20, 100, 0),
      issues: complexity > 10 ? ['å‡½æ•¸è¤‡é›œåº¦éé«˜'] : [],
      recommendations: complexity > 10 ? ['è€ƒæ…®é‡æ§‹å¤§å‹å‡½æ•¸'] : []
    };
  }
  
  // æ¸¬è©¦è¦†è“‹ç‡åˆ†æ
  analyzeCoverage(coverageData) {
    const { statements, branches, functions, lines } = coverageData;
    const avgCoverage = (statements + branches + functions + lines) / 4;
    
    return {
      score: avgCoverage,
      issues: avgCoverage < 80 ? ['æ¸¬è©¦è¦†è“‹ç‡ä¸è¶³'] : [],
      recommendations: avgCoverage < 80 ? ['å¢åŠ å–®å…ƒæ¸¬è©¦'] : []
    };
  }
  
  // ç¨‹å¼ç¢¼é‡è¤‡åˆ†æ
  analyzeDuplication(jscpdReport) {
    const duplicationPercentage = jscpdReport.statistics.total.percentage;
    
    return {
      score: this.normalizeScore(duplicationPercentage, 0, 20, 100, 0),
      issues: duplicationPercentage > 5 ? ['ç¨‹å¼ç¢¼é‡è¤‡ç‡éé«˜'] : [],
      recommendations: duplicationPercentage > 5 ? ['æå–å…±ç”¨æ¨¡çµ„'] : []
    };
  }
  
  // ä¾è³´åˆ†æ
  analyzeDependencies(packageJson) {
    const deps = Object.keys(packageJson.dependencies || {});
    const devDeps = Object.keys(packageJson.devDependencies || {});
    const totalDeps = deps.length + devDeps.length;
    
    // æª¢æŸ¥éæ™‚ä¾è³´
    const outdatedCount = this.checkOutdatedDependencies(deps);
    
    return {
      score: this.normalizeScore(outdatedCount, 0, 10, 100, 0),
      issues: outdatedCount > 5 ? ['éå¤šéæ™‚ä¾è³´'] : [],
      recommendations: outdatedCount > 0 ? ['æ›´æ–°ä¾è³´å¥—ä»¶'] : []
    };
  }
  
  // ç¶œåˆè©•ä¼°
  generateReport() {
    const overallScore = Object.values(this.metrics)
      .reduce((sum, score) => sum + score, 0) / Object.keys(this.metrics).length;
    
    let level;
    if (overallScore >= 80) level = 'LOW';
    else if (overallScore >= 60) level = 'MEDIUM';
    else if (overallScore >= 40) level = 'HIGH';
    else level = 'CRITICAL';
    
    return {
      overallScore,
      debtLevel: level,
      priority: this.calculatePriority(level),
      estimatedEffort: this.estimateRefactoringEffort(level),
      recommendations: this.generateRecommendations()
    };
  }
  
  calculatePriority(level) {
    const priorities = {
      CRITICAL: 1,
      HIGH: 2,
      MEDIUM: 3,
      LOW: 4
    };
    return priorities[level];
  }
  
  estimateRefactoringEffort(level) {
    const efforts = {
      CRITICAL: '8-12é€±',
      HIGH: '4-6é€±',
      MEDIUM: '2-3é€±',
      LOW: '1é€±ä»¥å…§'
    };
    return efforts[level];
  }
  
  normalizeScore(value, min, max, targetMax, targetMin) {
    return ((value - min) / (max - min)) * (targetMax - targetMin) + targetMin;
  }
}

// ä½¿ç”¨ç¯„ä¾‹
const analyzer = new TechnicalDebtAnalyzer();
const report = analyzer.generateReport();
console.log('æŠ€è¡“å‚µå‹™å ±å‘Š:', report);
```

---

## ğŸ”’ ç¬¬å››éƒ¨åˆ†ï¼šç½é›£æ¢å¾©èˆ‡å‚™ä»½

### 4.1 ç½é›£æ¢å¾©è¦åŠƒ

#### ğŸ¯ RTOèˆ‡RPOç›®æ¨™è¨­å®š

**é—œéµæŒ‡æ¨™å®šç¾©**ï¼š
- **RTO (Recovery Time Objective)**ï¼šå¾ç½é›£ç™¼ç”Ÿåˆ°æœå‹™æ¢å¾©çš„æœ€å¤§å®¹å¿æ™‚é–“
- **RPO (Recovery Point Objective)**ï¼šå¯æ¥å—çš„æœ€å¤§è³‡æ–™éºå¤±æ™‚é–“

**ä¸åŒæ¥­å‹™ç­‰ç´šçš„è¦æ±‚**ï¼š

| æ¥­å‹™ç­‰ç´š | RTO | RPO | æˆæœ¬ | ç¯„ä¾‹ |
|----------|-----|-----|------|------|
| **é—œéµ** | < 1å°æ™‚ | < 15åˆ†é˜ | æ¥µé«˜ | æ”¯ä»˜ç³»çµ±ã€äº¤æ˜“å¹³å° |
| **é‡è¦** | < 4å°æ™‚ | < 1å°æ™‚ | é«˜ | ç”¨æˆ¶ç®¡ç†ã€è¨‚å–®ç³»çµ± |
| **ä¸€èˆ¬** | < 24å°æ™‚ | < 4å°æ™‚ | ä¸­ç­‰ | å ±è¡¨ç³»çµ±ã€æ—¥èªŒåˆ†æ |
| **ä½** | < 72å°æ™‚ | < 24å°æ™‚ | ä½ | æ¸¬è©¦ç’°å¢ƒã€æ–‡æª”ç³»çµ± |

#### ğŸ—ºï¸ ç½é›£æ¢å¾©ç­–ç•¥

**å†·å‚™ä»½ (Cold Backup)**ï¼š
```bash
#!/bin/bash
# cold-backup.sh

BACKUP_DIR="/backup/$(date +%Y%m%d)"
DATABASE_NAME="production_db"
S3_BUCKET="myapp-backups"

echo "é–‹å§‹å†·å‚™ä»½æµç¨‹..."

# 1. å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p $BACKUP_DIR

# 2. è³‡æ–™åº«å‚™ä»½
echo "å‚™ä»½è³‡æ–™åº«..."
pg_dump $DATABASE_NAME | gzip > $BACKUP_DIR/database.sql.gz

# 3. æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆå‚™ä»½
echo "å‚™ä»½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ..."
tar -czf $BACKUP_DIR/application.tar.gz /opt/myapp

# 4. é…ç½®æª”æ¡ˆå‚™ä»½
echo "å‚™ä»½é…ç½®æª”æ¡ˆ..."
tar -czf $BACKUP_DIR/configs.tar.gz /etc/myapp

# 5. ä¸Šå‚³åˆ°é›²ç«¯å­˜å„²
echo "ä¸Šå‚³åˆ°S3..."
aws s3 sync $BACKUP_DIR s3://$S3_BUCKET/$(basename $BACKUP_DIR)

# 6. é©—è­‰å‚™ä»½å®Œæ•´æ€§
echo "é©—è­‰å‚™ä»½..."
if aws s3 ls s3://$S3_BUCKET/$(basename $BACKUP_DIR)/ | grep -q "database.sql.gz"; then
    echo "âœ… å‚™ä»½å®Œæˆä¸¦é©—è­‰æˆåŠŸ"
    
    # æ¸…ç†æœ¬åœ°å‚™ä»½ (ä¿ç•™7å¤©)
    find /backup -type d -mtime +7 -exec rm -rf {} \;
else
    echo "âŒ å‚™ä»½é©—è­‰å¤±æ•—"
    exit 1
fi
```

**ç†±å‚™ä»½ (Hot Backup) - PostgreSQL**ï¼š
```bash
#!/bin/bash
# hot-backup-postgres.sh

BACKUP_DIR="/backup/hot/$(date +%Y%m%d_%H%M%S)"
WAL_ARCHIVE_DIR="/backup/wal"

# 1. é–‹å§‹åŸºç¤å‚™ä»½
echo "é–‹å§‹ç†±å‚™ä»½..."
psql -c "SELECT pg_start_backup('hot_backup_$(date +%Y%m%d_%H%M%S)');"

# 2. è¤‡è£½è³‡æ–™æª”æ¡ˆ
mkdir -p $BACKUP_DIR
rsync -av --exclude='pg_wal/*' /var/lib/postgresql/data/ $BACKUP_DIR/

# 3. çµæŸåŸºç¤å‚™ä»½
psql -c "SELECT pg_stop_backup();"

# 4. è¤‡è£½å¿…è¦çš„WALæª”æ¡ˆ
cp $WAL_ARCHIVE_DIR/* $BACKUP_DIR/pg_wal/

echo "âœ… ç†±å‚™ä»½å®Œæˆ: $BACKUP_DIR"
```

**ä¸»å¾è¤‡è£½é…ç½®**ï¼š
```sql
-- ä¸»è³‡æ–™åº«é…ç½® (postgresql.conf)
wal_level = replica
max_wal_senders = 3
wal_keep_segments = 64
archive_mode = on
archive_command = 'cp %p /backup/wal/%f'

-- å‰µå»ºè¤‡è£½ç”¨æˆ¶
CREATE USER replication_user REPLICATION LOGIN PASSWORD 'secure_password';

-- pg_hba.conf
host replication replication_user 192.168.1.100/32 md5
```

```bash
# å¾è³‡æ–™åº«è¨­ç½®
#!/bin/bash
# setup-slave.sh

MASTER_HOST="192.168.1.50"
SLAVE_DATA_DIR="/var/lib/postgresql/slave"

# 1. åœæ­¢å¾è³‡æ–™åº«
systemctl stop postgresql-slave

# 2. æ¸…ç†è³‡æ–™ç›®éŒ„
rm -rf $SLAVE_DATA_DIR/*

# 3. å¾ä¸»è³‡æ–™åº«å¾©åˆ¶åŸºç¤å‚™ä»½
pg_basebackup -h $MASTER_HOST -D $SLAVE_DATA_DIR -U replication_user -W -v -P

# 4. é…ç½®æ¢å¾©è¨­ç½®
cat > $SLAVE_DATA_DIR/recovery.conf << EOF
standby_mode = 'on'
primary_conninfo = 'host=$MASTER_HOST port=5432 user=replication_user password=secure_password'
recovery_target_timeline = 'latest'
EOF

# 5. å•Ÿå‹•å¾è³‡æ–™åº«
systemctl start postgresql-slave

echo "âœ… å¾è³‡æ–™åº«è¨­ç½®å®Œæˆ"
```

### 4.2 å‚™ä»½ç­–ç•¥å¯¦æ–½

#### ğŸ’¾ 3-2-1å‚™ä»½ç­–ç•¥

**3-2-1åŸå‰‡**ï¼š
- **3**ä»½å‰¯æœ¬ï¼šåŸå§‹è³‡æ–™ + 2ä»½å‚™ä»½
- **2**ç¨®åª’é«”ï¼šä¸åŒé¡å‹çš„å­˜å„²åª’é«”
- **1**ä»½ç•°åœ°ï¼šè‡³å°‘1ä»½å‚™ä»½åœ¨ç•°åœ°

**è‡ªå‹•åŒ–å‚™ä»½è…³æœ¬**ï¼š
```bash
#!/bin/bash
# automated-backup.sh

set -e

# é…ç½®
APP_NAME="myapp"
BACKUP_ROOT="/backup"
LOCAL_BACKUP_DIR="$BACKUP_ROOT/local"
REMOTE_BACKUP_DIR="$BACKUP_ROOT/remote"
S3_BUCKET="myapp-disaster-recovery"
RETENTION_DAYS=30

# æ—¥èªŒå‡½æ•¸
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a /var/log/backup.log
}

# å‚™ä»½è³‡æ–™åº«
backup_database() {
    log "é–‹å§‹è³‡æ–™åº«å‚™ä»½..."
    
    local backup_file="$LOCAL_BACKUP_DIR/db_$(date +%Y%m%d_%H%M%S).sql.gz"
    mkdir -p $(dirname $backup_file)
    
    pg_dump $APP_NAME | gzip > $backup_file
    
    if [ $? -eq 0 ]; then
        log "âœ… è³‡æ–™åº«å‚™ä»½å®Œæˆ: $backup_file"
        echo $backup_file
    else
        log "âŒ è³‡æ–™åº«å‚™ä»½å¤±æ•—"
        exit 1
    fi
}

# å‚™ä»½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ
backup_application() {
    log "é–‹å§‹æ‡‰ç”¨ç¨‹å¼å‚™ä»½..."
    
    local backup_file="$LOCAL_BACKUP_DIR/app_$(date +%Y%m%d_%H%M%S).tar.gz"
    mkdir -p $(dirname $backup_file)
    
    tar -czf $backup_file \
        --exclude='node_modules' \
        --exclude='logs' \
        --exclude='.git' \
        /opt/$APP_NAME
    
    if [ $? -eq 0 ]; then
        log "âœ… æ‡‰ç”¨ç¨‹å¼å‚™ä»½å®Œæˆ: $backup_file"
        echo $backup_file
    else
        log "âŒ æ‡‰ç”¨ç¨‹å¼å‚™ä»½å¤±æ•—"
        exit 1
    fi
}

# ä¸Šå‚³åˆ°é›²ç«¯
upload_to_cloud() {
    local file=$1
    local filename=$(basename $file)
    
    log "ä¸Šå‚³ $filename åˆ°S3..."
    
    aws s3 cp $file s3://$S3_BUCKET/$(date +%Y/%m/%d)/$filename \
        --storage-class STANDARD_IA
    
    if [ $? -eq 0 ]; then
        log "âœ… é›²ç«¯ä¸Šå‚³å®Œæˆ: $filename"
    else
        log "âŒ é›²ç«¯ä¸Šå‚³å¤±æ•—: $filename"
        return 1
    fi
}

# è¤‡è£½åˆ°ç•°åœ°å­˜å„²
copy_to_remote() {
    local file=$1
    local remote_file="$REMOTE_BACKUP_DIR/$(basename $file)"
    
    log "è¤‡è£½åˆ°ç•°åœ°å­˜å„²..."
    mkdir -p $(dirname $remote_file)
    cp $file $remote_file
    
    if [ $? -eq 0 ]; then
        log "âœ… ç•°åœ°è¤‡è£½å®Œæˆ: $remote_file"
    else
        log "âŒ ç•°åœ°è¤‡è£½å¤±æ•—"
        return 1
    fi
}

# æ¸…ç†éæœŸå‚™ä»½
cleanup_old_backups() {
    log "æ¸…ç†éæœŸå‚™ä»½..."
    
    # æ¸…ç†æœ¬åœ°å‚™ä»½
    find $LOCAL_BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete
    
    # æ¸…ç†ç•°åœ°å‚™ä»½
    find $REMOTE_BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete
    
    # æ¸…ç†S3å‚™ä»½ (ä½¿ç”¨ç”Ÿå‘½é€±æœŸç­–ç•¥)
    log "âœ… éæœŸå‚™ä»½æ¸…ç†å®Œæˆ"
}

# é©—è­‰å‚™ä»½å®Œæ•´æ€§
verify_backup() {
    local db_backup=$1
    local app_backup=$2
    
    log "é©—è­‰å‚™ä»½å®Œæ•´æ€§..."
    
    # é©—è­‰è³‡æ–™åº«å‚™ä»½
    if gzip -t $db_backup; then
        log "âœ… è³‡æ–™åº«å‚™ä»½æª”æ¡ˆå®Œæ•´"
    else
        log "âŒ è³‡æ–™åº«å‚™ä»½æª”æ¡ˆæå£"
        return 1
    fi
    
    # é©—è­‰æ‡‰ç”¨ç¨‹å¼å‚™ä»½
    if tar -tzf $app_backup > /dev/null; then
        log "âœ… æ‡‰ç”¨ç¨‹å¼å‚™ä»½æª”æ¡ˆå®Œæ•´"
    else
        log "âŒ æ‡‰ç”¨ç¨‹å¼å‚™ä»½æª”æ¡ˆæå£"
        return 1
    fi
}

# ä¸»æµç¨‹
main() {
    log "ğŸš€ é–‹å§‹è‡ªå‹•åŒ–å‚™ä»½æµç¨‹"
    
    # 1. å‚™ä»½è³‡æ–™åº«å’Œæ‡‰ç”¨ç¨‹å¼
    db_backup=$(backup_database)
    app_backup=$(backup_application)
    
    # 2. é©—è­‰å‚™ä»½å®Œæ•´æ€§
    verify_backup $db_backup $app_backup
    
    # 3. å¯¦æ–½3-2-1ç­–ç•¥
    # ç¬¬1ä»½ï¼šæœ¬åœ°å­˜å„² (å·²å®Œæˆ)
    # ç¬¬2ä»½ï¼šç•°åœ°å­˜å„²
    copy_to_remote $db_backup
    copy_to_remote $app_backup
    
    # ç¬¬3ä»½ï¼šé›²ç«¯å­˜å„²
    upload_to_cloud $db_backup
    upload_to_cloud $app_backup
    
    # 4. æ¸…ç†éæœŸå‚™ä»½
    cleanup_old_backups
    
    log "ğŸ‰ å‚™ä»½æµç¨‹å®Œæˆ"
}

# åŸ·è¡Œä¸»æµç¨‹
main

# ç™¼é€å‚™ä»½å ±å‘Š
if [ $? -eq 0 ]; then
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"âœ… è‡ªå‹•å‚™ä»½æˆåŠŸå®Œæˆ"}' \
        $SLACK_WEBHOOK_URL
else
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"âŒ è‡ªå‹•å‚™ä»½å¤±æ•—ï¼Œè«‹æª¢æŸ¥"}' \
        $SLACK_WEBHOOK_URL
fi
```

### 4.3 ç½é›£æ¢å¾©æ¼”ç·´

#### ğŸ­ æ¢å¾©æ¸¬è©¦è…³æœ¬

```bash
#!/bin/bash
# disaster-recovery-test.sh

TEST_ENV="dr-test"
BACKUP_DATE=${1:-$(date -d "yesterday" +%Y%m%d)}
S3_BUCKET="myapp-disaster-recovery"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# æ¢å¾©è³‡æ–™åº«
restore_database() {
    log "é–‹å§‹æ¢å¾©è³‡æ–™åº«æ¸¬è©¦..."
    
    # 1. ä¸‹è¼‰å‚™ä»½æª”æ¡ˆ
    local backup_file="db_backup_$BACKUP_DATE.sql.gz"
    aws s3 cp s3://$S3_BUCKET/$BACKUP_DATE/$backup_file /tmp/
    
    # 2. å»ºç«‹æ¸¬è©¦è³‡æ–™åº«
    createdb ${TEST_ENV}_db
    
    # 3. æ¢å¾©è³‡æ–™
    gunzip -c /tmp/$backup_file | psql ${TEST_ENV}_db
    
    if [ $? -eq 0 ]; then
        log "âœ… è³‡æ–™åº«æ¢å¾©æ¸¬è©¦æˆåŠŸ"
        return 0
    else
        log "âŒ è³‡æ–™åº«æ¢å¾©æ¸¬è©¦å¤±æ•—"
        return 1
    fi
}

# æ¢å¾©æ‡‰ç”¨ç¨‹å¼
restore_application() {
    log "é–‹å§‹æ¢å¾©æ‡‰ç”¨ç¨‹å¼æ¸¬è©¦..."
    
    # 1. ä¸‹è¼‰æ‡‰ç”¨ç¨‹å¼å‚™ä»½
    local backup_file="app_backup_$BACKUP_DATE.tar.gz"
    aws s3 cp s3://$S3_BUCKET/$BACKUP_DATE/$backup_file /tmp/
    
    # 2. è§£å£“åˆ°æ¸¬è©¦ç›®éŒ„
    mkdir -p /opt/${TEST_ENV}
    tar -xzf /tmp/$backup_file -C /opt/${TEST_ENV}
    
    # 3. æ›´æ–°é…ç½®
    sed -i "s/production_db/${TEST_ENV}_db/g" /opt/${TEST_ENV}/config/database.yml
    
    if [ $? -eq 0 ]; then
        log "âœ… æ‡‰ç”¨ç¨‹å¼æ¢å¾©æ¸¬è©¦æˆåŠŸ"
        return 0
    else
        log "âŒ æ‡‰ç”¨ç¨‹å¼æ¢å¾©æ¸¬è©¦å¤±æ•—"
        return 1
    fi
}

# åŠŸèƒ½é©—è­‰æ¸¬è©¦
verify_functionality() {
    log "é–‹å§‹åŠŸèƒ½é©—è­‰æ¸¬è©¦..."
    
    # ç­‰å¾…æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•
    sleep 30
    
    # å¥åº·æª¢æŸ¥
    if curl -f http://localhost:3001/health; then
        log "âœ… å¥åº·æª¢æŸ¥é€šé"
    else
        log "âŒ å¥åº·æª¢æŸ¥å¤±æ•—"
        return 1
    fi
    
    # é—œéµåŠŸèƒ½æ¸¬è©¦
    local test_results=$(npm run test:critical -- --env=$TEST_ENV)
    if echo "$test_results" | grep -q "All tests passed"; then
        log "âœ… é—œéµåŠŸèƒ½æ¸¬è©¦é€šé"
        return 0
    else
        log "âŒ é—œéµåŠŸèƒ½æ¸¬è©¦å¤±æ•—"
        return 1
    fi
}

# æ¸…ç†æ¸¬è©¦ç’°å¢ƒ
cleanup_test_environment() {
    log "æ¸…ç†æ¸¬è©¦ç’°å¢ƒ..."
    
    # åœæ­¢æ¸¬è©¦æ‡‰ç”¨ç¨‹å¼
    pkill -f "${TEST_ENV}"
    
    # åˆªé™¤æ¸¬è©¦è³‡æ–™åº«
    dropdb ${TEST_ENV}_db
    
    # åˆªé™¤æ¸¬è©¦æª”æ¡ˆ
    rm -rf /opt/${TEST_ENV}
    rm -f /tmp/*backup*
    
    log "âœ… æ¸¬è©¦ç’°å¢ƒæ¸…ç†å®Œæˆ"
}

# ç”Ÿæˆæ¢å¾©å ±å‘Š
generate_report() {
    local db_result=$1
    local app_result=$2
    local func_result=$3
    
    local report_file="/tmp/dr_test_report_$(date +%Y%m%d_%H%M%S).json"
    
    cat > $report_file << EOF
{
    "test_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "backup_date": "$BACKUP_DATE",
    "results": {
        "database_restore": $([ $db_result -eq 0 ] && echo "true" || echo "false"),
        "application_restore": $([ $app_result -eq 0 ] && echo "true" || echo "false"),
        "functionality_test": $([ $func_result -eq 0 ] && echo "true" || echo "false")
    },
    "overall_success": $([ $db_result -eq 0 ] && [ $app_result -eq 0 ] && [ $func_result -eq 0 ] && echo "true" || echo "false"),
    "rto_achieved": "$(date -d "$start_time + 1 hour" +%H:%M:%S)",
    "recommendations": [
        "å®šæœŸåŸ·è¡Œæ¢å¾©æ¸¬è©¦",
        "å„ªåŒ–å‚™ä»½æª”æ¡ˆå¤§å°",
        "è‡ªå‹•åŒ–æ¢å¾©æµç¨‹"
    ]
}
EOF
    
    log "æ¢å¾©æ¸¬è©¦å ±å‘Šå·²ç”Ÿæˆ: $report_file"
    
    # ä¸Šå‚³å ±å‘Š
    aws s3 cp $report_file s3://$S3_BUCKET/reports/
}

# ä¸»è¦æ¢å¾©æ¸¬è©¦æµç¨‹
main() {
    local start_time=$(date)
    log "ğŸš€ é–‹å§‹ç½é›£æ¢å¾©æ¸¬è©¦ (å‚™ä»½æ—¥æœŸ: $BACKUP_DATE)"
    
    # åŸ·è¡Œæ¢å¾©æ¸¬è©¦
    restore_database
    local db_result=$?
    
    restore_application  
    local app_result=$?
    
    verify_functionality
    local func_result=$?
    
    # ç”Ÿæˆå ±å‘Š
    generate_report $db_result $app_result $func_result
    
    # æ¸…ç†ç’°å¢ƒ
    cleanup_test_environment
    
    # ç¸½çµ
    if [ $db_result -eq 0 ] && [ $app_result -eq 0 ] && [ $func_result -eq 0 ]; then
        log "ğŸ‰ ç½é›£æ¢å¾©æ¸¬è©¦å…¨éƒ¨é€šé"
        return 0
    else
        log "âŒ ç½é›£æ¢å¾©æ¸¬è©¦å­˜åœ¨å•é¡Œï¼Œè«‹æª¢æŸ¥"
        return 1
    fi
}

# åŸ·è¡Œæ¸¬è©¦
main
```

---

## ğŸ“ ç¬¬äº”éƒ¨åˆ†ï¼šä½¿ç”¨è€…æ”¯æ´èˆ‡æ–‡ä»¶ç®¡ç†

### 5.1 ä½¿ç”¨è€…æ”¯æ´é«”ç³»

#### ğŸ¯ æ”¯æ´å±¤ç´šè¨­è¨ˆ

**å¤šå±¤ç´šæ”¯æ´æ¶æ§‹**ï¼š
```
ç¬¬ä¸€å±¤ (L1) - åŸºæœ¬æ”¯æ´
â”œâ”€â”€ å¸¸è¦‹å•é¡Œè§£ç­”
â”œâ”€â”€ è‡ªåŠ©æœå‹™å·¥å…·
â”œâ”€â”€ èŠå¤©æ©Ÿå™¨äºº
â””â”€â”€ åŸºæœ¬å•é¡Œè™•ç†

ç¬¬äºŒå±¤ (L2) - æŠ€è¡“æ”¯æ´
â”œâ”€â”€ è¤‡é›œå•é¡Œè¨ºæ–·
â”œâ”€â”€ ç³»çµ±é…ç½®å”åŠ©
â”œâ”€â”€ éŒ¯èª¤æ’é™¤
â””â”€â”€ å‡ç´šèˆ‡æ›´æ–°

ç¬¬ä¸‰å±¤ (L3) - å°ˆå®¶æ”¯æ´
â”œâ”€â”€ æ·±åº¦æŠ€è¡“å•é¡Œ
â”œâ”€â”€ å®¢è£½åŒ–é–‹ç™¼
â”œâ”€â”€ æ¶æ§‹è«®è©¢
â””â”€â”€ ç·Šæ€¥äº‹ä»¶è™•ç†
```

#### ğŸ“Š æ”¯æ´æŒ‡æ¨™èˆ‡SLA

**æœå‹™æ°´æº–å”è­° (SLA)**ï¼š

| æ”¯æ´ç­‰ç´š | å›æ‡‰æ™‚é–“ | è§£æ±ºæ™‚é–“ | å¯ç”¨æ€§ | æˆæœ¬ |
|----------|----------|----------|--------|------|
| **åŸºæœ¬** | 24å°æ™‚ | 5å€‹å·¥ä½œæ—¥ | 99% | ä½ |
| **æ¨™æº–** | 4å°æ™‚ | 2å€‹å·¥ä½œæ—¥ | 99.5% | ä¸­ |
| **é«˜ç´š** | 1å°æ™‚ | 8å°æ™‚ | 99.9% | é«˜ |
| **ä¼æ¥­** | 15åˆ†é˜ | 2å°æ™‚ | 99.99% | æ¥µé«˜ |

### 5.2 æ–‡ä»¶ç®¡ç†é«”ç³»

#### ğŸ“š æ–‡ä»¶åˆ†é¡æ¶æ§‹

**æŠ€è¡“æ–‡ä»¶çµæ§‹**ï¼š
```
æŠ€è¡“æ–‡ä»¶åº«
â”œâ”€â”€ ä½¿ç”¨è€…æ–‡ä»¶
â”‚   â”œâ”€â”€ ä½¿ç”¨è€…æ‰‹å†Š
â”‚   â”œâ”€â”€ å¿«é€Ÿå…¥é–€æŒ‡å—
â”‚   â”œâ”€â”€ å¸¸è¦‹å•é¡ŒFAQ
â”‚   â””â”€â”€ å½±ç‰‡æ•™å­¸
â”œâ”€â”€ é–‹ç™¼è€…æ–‡ä»¶
â”‚   â”œâ”€â”€ APIæ–‡ä»¶
â”‚   â”œâ”€â”€ SDKä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ æ¶æ§‹è¨­è¨ˆæ–‡ä»¶
â”‚   â””â”€â”€ é–‹ç™¼ç’°å¢ƒè¨­ç½®
â”œâ”€â”€ é‹ç¶­æ–‡ä»¶
â”‚   â”œâ”€â”€ éƒ¨ç½²æŒ‡å—
â”‚   â”œâ”€â”€ ç›£æ§è¨­ç½®
â”‚   â”œâ”€â”€ æ•…éšœæ’é™¤
â”‚   â””â”€â”€ å‚™ä»½æ¢å¾©
â””â”€â”€ æµç¨‹æ–‡ä»¶
    â”œâ”€â”€ é–‹ç™¼æµç¨‹
    â”œâ”€â”€ æ¸¬è©¦æµç¨‹
    â”œâ”€â”€ ç™¼å¸ƒæµç¨‹
    â””â”€â”€ æ”¯æ´æµç¨‹
```

#### ğŸ“ APIæ–‡ä»¶è‡ªå‹•ç”Ÿæˆ

**OpenAPI/Swaggeræ–‡ä»¶ç”Ÿæˆ**ï¼š
```javascript
// swagger-config.js
const swaggerJsdoc = require('swagger-jsdoc');
const swaggerUi = require('swagger-ui-express');

const options = {
  definition: {
    openapi: '3.0.0',
    info: {
      title: 'MyApp API',
      version: '1.0.0',
      description: 'MyApp APIæ–‡ä»¶',
      contact: {
        name: 'APIæ”¯æ´åœ˜éšŠ',
        email: 'api-support@myapp.com'
      }
    },
    servers: [
      {
        url: 'https://api.myapp.com/v1',
        description: 'ç”Ÿç”¢ç’°å¢ƒ'
      },
      {
        url: 'https://staging-api.myapp.com/v1', 
        description: 'æ¸¬è©¦ç’°å¢ƒ'
      }
    ],
    components: {
      securitySchemes: {
        bearerAuth: {
          type: 'http',
          scheme: 'bearer',
          bearerFormat: 'JWT'
        }
      }
    }
  },
  apis: ['./routes/*.js'], // APIè·¯ç”±æª”æ¡ˆè·¯å¾‘
};

const specs = swaggerJsdoc(options);

module.exports = { specs, swaggerUi };

// ä½¿ç”¨ç¯„ä¾‹ - routes/users.js
/**
 * @swagger
 * components:
 *   schemas:
 *     User:
 *       type: object
 *       required:
 *         - name
 *         - email
 *       properties:
 *         id:
 *           type: integer
 *           description: ä½¿ç”¨è€…å”¯ä¸€è­˜åˆ¥ç¢¼
 *         name:
 *           type: string
 *           description: ä½¿ç”¨è€…å§“å
 *         email:
 *           type: string
 *           format: email
 *           description: ä½¿ç”¨è€…é›»å­éƒµä»¶
 *         createdAt:
 *           type: string
 *           format: date-time
 *           description: å»ºç«‹æ™‚é–“
 *       example:
 *         id: 1
 *         name: å¼µå°æ˜
 *         email: ming@example.com
 *         createdAt: 2024-03-15T10:30:00Z
 */

/**
 * @swagger
 * /users:
 *   get:
 *     summary: å–å¾—ä½¿ç”¨è€…æ¸…å–®
 *     tags: [Users]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: page
 *         schema:
 *           type: integer
 *           minimum: 1
 *           default: 1
 *         description: é ç¢¼
 *       - in: query
 *         name: limit
 *         schema:
 *           type: integer
 *           minimum: 1
 *           maximum: 100
 *           default: 20
 *         description: æ¯é ç­†æ•¸
 *     responses:
 *       200:
 *         description: æˆåŠŸå–å¾—ä½¿ç”¨è€…æ¸…å–®
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 users:
 *                   type: array
 *                   items:
 *                     $ref: '#/components/schemas/User'
 *                 totalPages:
 *                   type: integer
 *                 currentPage:
 *                   type: integer
 *                 total:
 *                   type: integer
 *       401:
 *         description: æœªæˆæ¬Š
 *       500:
 *         description: ä¼ºæœå™¨éŒ¯èª¤
 */
router.get('/users', authenticateToken, async (req, res) => {
  try {
    const { page = 1, limit = 20 } = req.query;
    const users = await userService.getUsers(page, limit);
    res.json(users);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

/**
 * @swagger
 * /users:
 *   post:
 *     summary: å»ºç«‹æ–°ä½¿ç”¨è€…
 *     tags: [Users]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required:
 *               - name
 *               - email
 *               - password
 *             properties:
 *               name:
 *                 type: string
 *                 example: ç‹å°è¯
 *               email:
 *                 type: string
 *                 format: email
 *                 example: wang@example.com
 *               password:
 *                 type: string
 *                 minLength: 8
 *                 example: securePassword123
 *     responses:
 *       201:
 *         description: ä½¿ç”¨è€…å»ºç«‹æˆåŠŸ
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/User'
 *       400:
 *         description: è¼¸å…¥è³‡æ–™ç„¡æ•ˆ
 *       409:
 *         description: é›»å­éƒµä»¶å·²å­˜åœ¨
 *       500:
 *         description: ä¼ºæœå™¨éŒ¯èª¤
 */
router.post('/users', authenticateToken, async (req, res) => {
  try {
    const userData = req.body;
    const newUser = await userService.createUser(userData);
    res.status(201).json(newUser);
  } catch (error) {
    if (error.code === 'DUPLICATE_EMAIL') {
      res.status(409).json({ error: 'é›»å­éƒµä»¶å·²å­˜åœ¨' });
    } else {
      res.status(500).json({ error: error.message });
    }
  }
});
```

#### ğŸ“– è‡ªå‹•åŒ–æ–‡ä»¶ç™¼å¸ƒ

**æ–‡ä»¶CI/CDæµç¨‹**ï¼š
```yaml
# .github/workflows/docs.yml
name: æ–‡ä»¶ç™¼å¸ƒ

on:
  push:
    branches: [ main ]
    paths: 
      - 'docs/**'
      - 'routes/**'
      - 'swagger-config.js'

jobs:
  build-docs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v3
    
    - name: è¨­å®šNode.js
      uses: actions/setup-node@v3
      with:
        node-version: 18
        cache: 'npm'
    
    - name: å®‰è£ä¾è³´
      run: npm ci
    
    - name: ç”ŸæˆAPIæ–‡ä»¶
      run: |
        npm run docs:generate
        npm run docs:build
    
    - name: éƒ¨ç½²åˆ°GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./docs/dist
    
    - name: ç™¼é€é€šçŸ¥
      uses: 8398a7/action-slack@v3
      with:
        status: success
        text: 'ğŸ“š APIæ–‡ä»¶å·²æ›´æ–°: https://myapp.github.io/api-docs'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

---

## ğŸ”„ ç¬¬å…­éƒ¨åˆ†ï¼šç”Ÿå‘½é€±æœŸç®¡ç†

### 6.1 è»Ÿé«”ç”Ÿå‘½é€±æœŸéšæ®µ

#### ğŸ“ˆ ç”¢å“æˆç†Ÿåº¦æ›²ç·š

```
æ•ˆèƒ½/æ¡ç”¨ç‡
    â†‘
    â”‚     æˆç†ŸæœŸ
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â•±           â•²
    â”‚  â•±             â•² è¡°é€€æœŸ
    â”‚ â•± æˆé•·æœŸ        â•²
    â”‚â•±                 â•²
å¼•å…¥æœŸ                  æ·˜æ±°æœŸ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ æ™‚é–“
```

**å„éšæ®µç‰¹å¾µèˆ‡ç­–ç•¥**ï¼š

| éšæ®µ | ç‰¹å¾µ | ç­–ç•¥é‡é» | æŠ€è¡“è² å‚µ | ç¶­è­·é‡é» |
|------|------|----------|----------|----------|
| **å¼•å…¥æœŸ** | åŠŸèƒ½åŸºç¤ã€ä½¿ç”¨è€…å°‘ | å¿«é€Ÿé–‹ç™¼ã€åŠŸèƒ½é©—è­‰ | å¯æ¥å—è¼ƒé«˜ | éŒ¯èª¤ä¿®å¾© |
| **æˆé•·æœŸ** | ä½¿ç”¨è€…å¿«é€Ÿå¢é•· | æ•ˆèƒ½å„ªåŒ–ã€ç©©å®šæ€§ | ç©æ¥µç®¡ç† | æ“´å±•æ€§ |
| **æˆç†ŸæœŸ** | å¸‚å ´ç©©å®šã€åŠŸèƒ½å®Œæ•´ | æˆæœ¬æ§åˆ¶ã€æ•ˆç‡ | æŒçºŒé‡æ§‹ | å®‰å…¨æ€§ |
| **è¡°é€€æœŸ** | éœ€æ±‚ä¸‹é™ã€ç«¶çˆ­æ¿€çƒˆ | æœ€å°ç¶­è­·ã€é·ç§»æº–å‚™ | å‡çµæ–°å¢ | å¿…è¦ä¿®å¾© |

### 6.2 éºç•™ç³»çµ±ç®¡ç†

#### ğŸ›ï¸ éºç•™ç³»çµ±ç¾ä»£åŒ–ç­–ç•¥

**ç¾ä»£åŒ–æ–¹æ³•æ¯”è¼ƒ**ï¼š

| æ–¹æ³• | æˆæœ¬ | é¢¨éšª | æ™‚é–“ | é©ç”¨æƒ…å¢ƒ |
|------|------|------|------|----------|
| **ä¿æŒç¾ç‹€** | ä½ | é«˜ | çŸ­ | å³å°‡æ·˜æ±°çš„ç³»çµ± |
| **å°è£** | ä½ | ä¸­ | çŸ­ | éœ€è¦å¿«é€Ÿæ•´åˆ |
| **é‡æ–°å¹³å°åŒ–** | ä¸­ | ä¸­ | ä¸­ | åŸºç¤è¨­æ–½è€èˆŠ |
| **é‡æ§‹** | é«˜ | ä¸­ | é•· | é‚è¼¯è¤‡é›œä½†åƒ¹å€¼é«˜ |
| **é‡å»º** | æ¥µé«˜ | é«˜ | æ¥µé•· | å®Œå…¨ä¸é©ç”¨ |

**çµæ®ºè€…æ¨¡å¼ (Strangler Fig Pattern)**ï¼š
```javascript
// legacy-migration-proxy.js
const express = require('express');
const { createProxyMiddleware } = require('http-proxy-middleware');

const app = express();

// é…ç½®è·¯ç”±æ˜ å°„
const routeConfig = {
  // å·²é·ç§»åˆ°æ–°ç³»çµ±çš„è·¯ç”±
  '/api/users': 'http://new-service:3000',
  '/api/orders': 'http://new-service:3000',
  
  // é‚„åœ¨éºç•™ç³»çµ±çš„è·¯ç”±
  '/api/legacy/reports': 'http://legacy-system:8080',
  '/api/legacy/billing': 'http://legacy-system:8080'
};

// ç‰¹æ€§é–‹é—œé…ç½®
const featureFlags = {
  newUserService: { enabled: true, rollout: 100 },
  newOrderService: { enabled: true, rollout: 50 },
  newReportService: { enabled: false, rollout: 0 }
};

// æ™ºèƒ½è·¯ç”±ä¸­é–“ä»¶
function intelligentRouter(req, res, next) {
  const path = req.path;
  const userId = req.headers['user-id'];
  
  // æª¢æŸ¥æ˜¯å¦æœ‰å°æ‡‰çš„æ–°æœå‹™
  for (const [route, target] of Object.entries(routeConfig)) {
    if (path.startsWith(route)) {
      // æª¢æŸ¥ç‰¹æ€§é–‹é—œ
      const featureName = getFeatureName(route);
      const feature = featureFlags[featureName];
      
      if (feature && feature.enabled) {
        // æ ¹æ“šæ¨å‡ºæ¯”ä¾‹æ±ºå®šè·¯ç”±
        const shouldUseNewService = shouldRouteToNewService(userId, feature.rollout);
        
        if (shouldUseNewService) {
          req.targetService = target;
          return next();
        }
      }
      
      // è·¯ç”±åˆ°éºç•™ç³»çµ±
      req.targetService = routeConfig['/api/legacy' + route.replace('/api', '')];
      return next();
    }
  }
  
  // é è¨­è·¯ç”±åˆ°éºç•™ç³»çµ±
  req.targetService = 'http://legacy-system:8080';
  next();
}

function shouldRouteToNewService(userId, rolloutPercentage) {
  // ä½¿ç”¨ä½¿ç”¨è€…IDçš„é›œæ¹Šå€¼ç¢ºä¿ä¸€è‡´æ€§
  const hash = require('crypto').createHash('md5').update(userId).digest('hex');
  const hashValue = parseInt(hash.substring(0, 8), 16);
  return (hashValue % 100) < rolloutPercentage;
}

function getFeatureName(route) {
  const mapping = {
    '/api/users': 'newUserService',
    '/api/orders': 'newOrderService',
    '/api/reports': 'newReportService'
  };
  return mapping[route] || 'default';
}

// å‹•æ…‹ä»£ç†ä¸­é–“ä»¶
app.use(intelligentRouter);

app.use('*', (req, res) => {
  const proxy = createProxyMiddleware({
    target: req.targetService,
    changeOrigin: true,
    onError: (err, req, res) => {
      console.error('ä»£ç†éŒ¯èª¤:', err);
      res.status(500).json({ error: 'æœå‹™æš«æ™‚ä¸å¯ç”¨' });
    },
    onProxyReq: (proxyReq, req, res) => {
      // æ·»åŠ è¿½è¹¤æ¨™é ­
      proxyReq.setHeader('X-Forwarded-Service', req.targetService);
      proxyReq.setHeader('X-Migration-Phase', 'strangler-pattern');
    }
  });
  
  proxy(req, res);
});

app.listen(3000, () => {
  console.log('é·ç§»ä»£ç†æœå‹™å™¨é‹è¡Œåœ¨ç«¯å£ 3000');
});
```

### 6.3 è»Ÿé«”çµ‚æ­¢è¨ˆç•«

#### ğŸ ç³»çµ±é€€å½¹æµç¨‹

**é€€å½¹è¨ˆç•«æª¢æŸ¥æ¸…å–®**ï¼š
```markdown
# è»Ÿé«”ç³»çµ±é€€å½¹è¨ˆç•«

## é€€å½¹æ±ºç­–
- [ ] æ¥­å‹™éœ€æ±‚è©•ä¼°
- [ ] æˆæœ¬æ•ˆç›Šåˆ†æ
- [ ] æ›¿ä»£æ–¹æ¡ˆç¢ºèª
- [ ] åˆ©å®³é—œä¿‚äººåŒæ„

## è³‡æ–™è™•ç†
- [ ] è³‡æ–™å‚™ä»½ç­–ç•¥
- [ ] è³‡æ–™é·ç§»è¨ˆç•«
- [ ] è³‡æ–™ä¿ç•™æ”¿ç­–
- [ ] è³‡æ–™éŠ·æ¯€ç¨‹åº

## ä½¿ç”¨è€…æºé€š
- [ ] é€€å½¹é€šçŸ¥è¨ˆç•«
- [ ] ä½¿ç”¨è€…åŸ¹è¨“
- [ ] æ”¯æ´æœå‹™éæ¸¡
- [ ] æ–‡ä»¶æ›´æ–°

## æŠ€è¡“æº–å‚™
- [ ] ç›¸ä¾æ€§åˆ†æ
- [ ] æœå‹™åœæ­¢è¨ˆç•«
- [ ] è³‡æºå›æ”¶
- [ ] æˆæ¬Šç®¡ç†

## æ³•è¦åˆè¦
- [ ] æ³•è¦è¦æ±‚æª¢æŸ¥
- [ ] ç¨½æ ¸æº–å‚™
- [ ] è¨˜éŒ„ä¿å­˜
- [ ] å ±å‘Šç¾©å‹™
```

**è‡ªå‹•åŒ–é€€å½¹è…³æœ¬**ï¼š
```bash
#!/bin/bash
# system-decommission.sh

SYSTEM_NAME=$1
DECOMMISSION_DATE=$2

if [ -z "$SYSTEM_NAME" ] || [ -z "$DECOMMISSION_DATE" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <ç³»çµ±åç¨±> <é€€å½¹æ—¥æœŸ>"
    exit 1
fi

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "/var/log/decommission_${SYSTEM_NAME}.log"
}

# éšæ®µ1ï¼šæº–å‚™éšæ®µ
prepare_decommission() {
    log "é–‹å§‹ç³»çµ±é€€å½¹æº–å‚™ï¼š$SYSTEM_NAME"
    
    # 1. å»ºç«‹æœ€çµ‚å‚™ä»½
    log "å»ºç«‹æœ€çµ‚ç³»çµ±å‚™ä»½..."
    ./backup-system.sh $SYSTEM_NAME final
    
    # 2. åŒ¯å‡ºé…ç½®
    log "åŒ¯å‡ºç³»çµ±é…ç½®..."
    kubectl get all -n $SYSTEM_NAME -o yaml > "${SYSTEM_NAME}_final_config.yaml"
    
    # 3. ç”Ÿæˆæœå‹™æ¸…å–®
    log "ç”Ÿæˆæœå‹™ä¾è³´æ¸…å–®..."
    kubectl get services -n $SYSTEM_NAME -o json | jq '.items[].metadata.name' > "${SYSTEM_NAME}_services.txt"
    
    # 4. é€šçŸ¥ç›£æ§ç³»çµ±
    log "æ›´æ–°ç›£æ§ç³»çµ±..."
    curl -X POST http://monitoring-api/systems/$SYSTEM_NAME/decommission \
        -H "Content-Type: application/json" \
        -d "{\"date\":\"$DECOMMISSION_DATE\",\"status\":\"preparing\"}"
}

# éšæ®µ2ï¼šæœå‹™åœæ­¢
stop_services() {
    log "é–‹å§‹åœæ­¢æœå‹™..."
    
    # 1. åœæ­¢æ–°è«‹æ±‚
    log "åœæ­¢è² è¼‰å¹³è¡¡å™¨æµé‡..."
    kubectl patch service $SYSTEM_NAME-service -p '{"spec":{"selector":{"app":"stopped"}}}'
    
    # 2. ç­‰å¾…ç¾æœ‰è«‹æ±‚å®Œæˆ
    log "ç­‰å¾…ç¾æœ‰è«‹æ±‚å®Œæˆ (30ç§’)..."
    sleep 30
    
    # 3. åœæ­¢æ‡‰ç”¨ç¨‹å¼
    log "åœæ­¢æ‡‰ç”¨ç¨‹å¼..."
    kubectl scale deployment $SYSTEM_NAME --replicas=0
    
    # 4. åœæ­¢è³‡æ–™åº«
    log "åœæ­¢è³‡æ–™åº«..."
    kubectl scale statefulset $SYSTEM_NAME-db --replicas=0
    
    log "âœ… æ‰€æœ‰æœå‹™å·²åœæ­¢"
}

# éšæ®µ3ï¼šè³‡æ–™è™•ç†
handle_data() {
    log "é–‹å§‹è³‡æ–™è™•ç†..."
    
    # 1. æœ€çµ‚è³‡æ–™åŒ¯å‡º
    log "åŒ¯å‡ºæœ€çµ‚è³‡æ–™..."
    pg_dump $SYSTEM_NAME | gzip > "${SYSTEM_NAME}_final_data.sql.gz"
    
    # 2. è³‡æ–™é©—è­‰
    log "é©—è­‰è³‡æ–™å®Œæ•´æ€§..."
    if gzip -t "${SYSTEM_NAME}_final_data.sql.gz"; then
        log "âœ… è³‡æ–™å‚™ä»½é©—è­‰æˆåŠŸ"
    else
        log "âŒ è³‡æ–™å‚™ä»½é©—è­‰å¤±æ•—"
        exit 1
    fi
    
    # 3. ä¸Šå‚³åˆ°é•·æœŸå„²å­˜
    log "ä¸Šå‚³åˆ°é•·æœŸå„²å­˜..."
    aws s3 cp "${SYSTEM_NAME}_final_data.sql.gz" "s3://long-term-storage/decommissioned/${SYSTEM_NAME}/"
    
    # 4. è³‡æ–™ä¿ç•™æ¨™è¨˜
    log "è¨­å®šè³‡æ–™ä¿ç•™æ¨™è¨˜..."
    aws s3api put-object-tagging \
        --bucket long-term-storage \
        --key "decommissioned/${SYSTEM_NAME}/${SYSTEM_NAME}_final_data.sql.gz" \
        --tagging 'TagSet=[{Key=RetentionPeriod,Value=7years},{Key=System,Value='$SYSTEM_NAME'}]'
}

# éšæ®µ4ï¼šè³‡æºæ¸…ç†
cleanup_resources() {
    log "é–‹å§‹è³‡æºæ¸…ç†..."
    
    # 1. åˆªé™¤Kubernetesè³‡æº
    log "åˆªé™¤Kubernetesè³‡æº..."
    kubectl delete namespace $SYSTEM_NAME
    
    # 2. æ¸…ç†è² è¼‰å¹³è¡¡å™¨
    log "æ¸…ç†è² è¼‰å¹³è¡¡å™¨..."
    aws elbv2 delete-load-balancer --load-balancer-arn $(aws elbv2 describe-load-balancers --names $SYSTEM_NAME --query 'LoadBalancers[0].LoadBalancerArn' --output text)
    
    # 3. åˆªé™¤è³‡æ–™åº«å¯¦ä¾‹
    log "åˆªé™¤è³‡æ–™åº«å¯¦ä¾‹..."
    aws rds delete-db-instance --db-instance-identifier $SYSTEM_NAME --final-db-snapshot-identifier "${SYSTEM_NAME}-final-snapshot"
    
    # 4. æ¸…ç†ç›£æ§é…ç½®
    log "æ¸…ç†ç›£æ§é…ç½®..."
    curl -X DELETE http://monitoring-api/systems/$SYSTEM_NAME
    
    log "âœ… è³‡æºæ¸…ç†å®Œæˆ"
}

# éšæ®µ5ï¼šæ–‡ä»¶æ­¸æª”
archive_documentation() {
    log "æ­¸æª”ç³»çµ±æ–‡ä»¶..."
    
    # 1. æ”¶é›†æ‰€æœ‰æ–‡ä»¶
    mkdir -p "/archive/${SYSTEM_NAME}"
    cp -r "/docs/${SYSTEM_NAME}" "/archive/${SYSTEM_NAME}/docs"
    cp "${SYSTEM_NAME}_final_config.yaml" "/archive/${SYSTEM_NAME}/"
    cp "${SYSTEM_NAME}_services.txt" "/archive/${SYSTEM_NAME}/"
    
    # 2. å»ºç«‹æ­¸æª”æ¸…å–®
    find "/archive/${SYSTEM_NAME}" -type f > "/archive/${SYSTEM_NAME}/archive_manifest.txt"
    
    # 3. ä¸Šå‚³æ­¸æª”
    tar -czf "${SYSTEM_NAME}_archive.tar.gz" "/archive/${SYSTEM_NAME}"
    aws s3 cp "${SYSTEM_NAME}_archive.tar.gz" "s3://document-archive/decommissioned/"
    
    log "âœ… æ–‡ä»¶æ­¸æª”å®Œæˆ"
}

# éšæ®µ6ï¼šæœ€çµ‚å ±å‘Š
generate_final_report() {
    log "ç”Ÿæˆé€€å½¹å ±å‘Š..."
    
    cat > "${SYSTEM_NAME}_decommission_report.md" << EOF
# ${SYSTEM_NAME} ç³»çµ±é€€å½¹å ±å‘Š

## åŸºæœ¬è³‡è¨Š
- **ç³»çµ±åç¨±**: ${SYSTEM_NAME}
- **é€€å½¹æ—¥æœŸ**: ${DECOMMISSION_DATE}
- **åŸ·è¡Œäººå“¡**: $(whoami)
- **é€€å½¹åŸå› **: [è«‹å¡«å…¥]

## åŸ·è¡Œæ‘˜è¦
- âœ… ç³»çµ±å‚™ä»½å®Œæˆ
- âœ… æœå‹™æ­£å¸¸åœæ­¢
- âœ… è³‡æ–™å®‰å…¨åŒ¯å‡º
- âœ… è³‡æºå®Œå…¨æ¸…ç†
- âœ… æ–‡ä»¶å®Œæ•´æ­¸æª”

## ä¿ç•™è³‡æº
- **è³‡æ–™å‚™ä»½**: s3://long-term-storage/decommissioned/${SYSTEM_NAME}/
- **æ–‡ä»¶æ­¸æª”**: s3://document-archive/decommissioned/${SYSTEM_NAME}_archive.tar.gz
- **æœ€çµ‚å¿«ç…§**: ${SYSTEM_NAME}-final-snapshot

## æ³¨æ„äº‹é …
- è³‡æ–™ä¿ç•™æœŸé™ï¼š7å¹´
- æ­¸æª”æ–‡ä»¶è¨ªå•ï¼šéœ€è¦ç”³è«‹
- ç·Šæ€¥æ¢å¾©ï¼šè¯ç¹«ç³»çµ±ç®¡ç†å“¡

## ç°½æ ¸
- ç³»çµ±ç®¡ç†å“¡: ________________
- æ¥­å‹™è² è²¬äºº: ________________
- è³‡è¨Šå®‰å…¨: ________________
EOF

    log "âœ… é€€å½¹å ±å‘Šå·²ç”Ÿæˆ"
}

# ä¸»æµç¨‹
main() {
    log "ğŸš€ é–‹å§‹ç³»çµ±é€€å½¹æµç¨‹ï¼š$SYSTEM_NAME"
    
    # ç¢ºèªé€€å½¹
    echo "âš ï¸  å³å°‡é€€å½¹ç³»çµ±ï¼š$SYSTEM_NAME"
    echo "é€€å½¹æ—¥æœŸï¼š$DECOMMISSION_DATE"
    echo "æ­¤æ“ä½œä¸å¯é€†ï¼Œè«‹ç¢ºèª (è¼¸å…¥ 'CONFIRM' ç¹¼çºŒ):"
    read confirmation
    
    if [ "$confirmation" != "CONFIRM" ]; then
        log "âŒ é€€å½¹æ“ä½œå·²å–æ¶ˆ"
        exit 1
    fi
    
    # åŸ·è¡Œé€€å½¹æ­¥é©Ÿ
    prepare_decommission
    stop_services
    handle_data
    cleanup_resources
    archive_documentation
    generate_final_report
    
    log "ğŸ‰ ç³»çµ±é€€å½¹å®Œæˆï¼š$SYSTEM_NAME"
    
    # ç™¼é€é€šçŸ¥
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"âœ… ç³»çµ± ${SYSTEM_NAME} å·²æˆåŠŸé€€å½¹\"}" \
        $SLACK_WEBHOOK_URL
}

# åŸ·è¡Œä¸»æµç¨‹
main
```

---

## ğŸƒâ€â™‚ï¸ å¯¦å‹™ç·´ç¿’

### ç·´ç¿’1ï¼šéƒ¨ç½²ç­–ç•¥è¨­è¨ˆèˆ‡å¯¦ä½œ

**å°ˆæ¡ˆèƒŒæ™¯**ï¼š
ç‚ºã€Œç·šä¸Šå­¸ç¿’å¹³å°ã€è¨­è¨ˆå®Œæ•´çš„å¤šç’°å¢ƒéƒ¨ç½²ç­–ç•¥ã€‚

**ç³»çµ±æ¶æ§‹**ï¼š
- å‰ç«¯ï¼šReact SPA
- å¾Œç«¯ï¼šNode.js API
- è³‡æ–™åº«ï¼šPostgreSQL
- å¿«å–ï¼šRedis
- æª”æ¡ˆå„²å­˜ï¼šAWS S3

**ä»»å‹™1.1ï¼šç’°å¢ƒæ¶æ§‹è¨­è¨ˆ**
è¨­è¨ˆå››å€‹ç’°å¢ƒçš„å®Œæ•´æ¶æ§‹ï¼š
1. **é–‹ç™¼ç’°å¢ƒ (Development)**
   - æœ¬åœ°Docker Composeé…ç½®
   - ç†±é‡è¼‰é–‹ç™¼ç’°å¢ƒ
   - æ¨¡æ“¬æ•¸æ“šè¨­å®š

2. **æ¸¬è©¦ç’°å¢ƒ (Testing)**
   - è‡ªå‹•åŒ–æ¸¬è©¦åŸ·è¡Œç’°å¢ƒ
   - CI/CDæ•´åˆé…ç½®
   - æ¸¬è©¦æ•¸æ“šç®¡ç†

3. **é ç”¢ç’°å¢ƒ (Staging)**
   - ç”Ÿç”¢ç’°å¢ƒå®Œå…¨è¤‡è£½
   - æ•ˆèƒ½æ¸¬è©¦ç’°å¢ƒ
   - ä½¿ç”¨è€…é©—æ”¶æ¸¬è©¦

4. **ç”Ÿç”¢ç’°å¢ƒ (Production)**
   - é«˜å¯ç”¨æ€§é…ç½®
   - è² è¼‰å¹³è¡¡è¨­è¨ˆ
   - ç›£æ§å‘Šè­¦è¨­ç½®

**ä»»å‹™1.2ï¼šéƒ¨ç½²æµç¨‹å¯¦ä½œ**
å¯¦ä½œä¸‰ç¨®éƒ¨ç½²ç­–ç•¥ï¼š

1. **è—ç¶ éƒ¨ç½²è…³æœ¬**
```bash
#!/bin/bash
# å»ºç«‹è—ç¶ éƒ¨ç½²è‡ªå‹•åŒ–è…³æœ¬
# è¦æ±‚ï¼šé›¶åœæ©Ÿã€å¿«é€Ÿå›å¾©ã€å¥åº·æª¢æŸ¥
```

2. **é‡‘çµ²é›€éƒ¨ç½²é…ç½®**
```yaml
# ä½¿ç”¨Istioæˆ–NGINXå¯¦ä½œé‡‘çµ²é›€éƒ¨ç½²
# è¦æ±‚ï¼šæµé‡åˆ†é…ã€æŒ‡æ¨™ç›£æ§ã€è‡ªå‹•å›å¾©
```

3. **æ»¾å‹•æ›´æ–°ç­–ç•¥**
```yaml
# Kubernetesæ»¾å‹•æ›´æ–°é…ç½®
# è¦æ±‚ï¼šå¹³æ»‘æ›´æ–°ã€è³‡æºæ§åˆ¶ã€å¤±æ•—è™•ç†
```

**ä»»å‹™1.3ï¼šCI/CD Pipelineå»ºç«‹**
å»ºç«‹å®Œæ•´çš„GitHub Actionså·¥ä½œæµï¼š
- ç¨‹å¼ç¢¼æª¢æŸ¥å’Œæ¸¬è©¦
- Dockeræ˜ åƒå»ºç½®
- å®‰å…¨æƒæ
- å¤šç’°å¢ƒéƒ¨ç½²
- éƒ¨ç½²é©—è­‰

**æäº¤æˆæœ**ï¼š
- å¤šç’°å¢ƒæ¶æ§‹è¨­è¨ˆåœ–
- å®Œæ•´çš„éƒ¨ç½²è…³æœ¬
- CI/CD Pipelineé…ç½®
- éƒ¨ç½²æ‰‹å†Šæ–‡ä»¶

### ç·´ç¿’2ï¼šç›£æ§èˆ‡å‘Šè­¦ç³»çµ±å»ºç«‹

**ä»»å‹™2.1ï¼šPrometheusç›£æ§è¨­ç½®**
ç‚ºå­¸ç¿’å¹³å°å»ºç«‹å®Œæ•´ç›£æ§ç³»çµ±ï¼š

1. **æ‡‰ç”¨å±¤æŒ‡æ¨™**
   - HTTPè«‹æ±‚æŒ‡æ¨™
   - æ¥­å‹™æŒ‡æ¨™ï¼ˆè¨»å†Šæ•¸ã€èª²ç¨‹å®Œæˆç‡ï¼‰
   - éŒ¯èª¤ç‡å’Œå»¶é²æŒ‡æ¨™

2. **åŸºç¤è¨­æ–½æŒ‡æ¨™**
   - ç³»çµ±è³‡æºä½¿ç”¨ç‡
   - è³‡æ–™åº«æ•ˆèƒ½æŒ‡æ¨™
   - ç¶²è·¯æµé‡æŒ‡æ¨™

3. **Grafanaå„€è¡¨æ¿**
   - ç³»çµ±æ¦‚è¦½å„€è¡¨æ¿
   - æ‡‰ç”¨ç¨‹å¼æ•ˆèƒ½å„€è¡¨æ¿
   - æ¥­å‹™æŒ‡æ¨™å„€è¡¨æ¿

**ä»»å‹™2.2ï¼šå‘Šè­¦è¦å‰‡è¨­è¨ˆ**
è¨­è¨ˆåˆ†å±¤å‘Šè­¦ç³»çµ±ï¼š

```yaml
# ç¯„ä¾‹å‘Šè­¦è¦å‰‡çµæ§‹
groups:
- name: critical-alerts
  rules:
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "æœå‹™åœæ­¢é‹è¡Œ"
      
- name: performance-alerts
  rules:
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
```

**ä»»å‹™2.3ï¼šæ—¥èªŒç®¡ç†ç³»çµ±**
å»ºç«‹ELK Stackæ—¥èªŒç®¡ç†ï¼š
- Elasticsearché›†ç¾¤è¨­ç½®
- Logstashæ—¥èªŒè™•ç†
- Kibanaè¦–è¦ºåŒ–é…ç½®
- æ—¥èªŒè¼ªè½‰å’Œä¿ç•™ç­–ç•¥

**æäº¤æˆæœ**ï¼š
- Prometheusé…ç½®æª”æ¡ˆ
- Grafanaå„€è¡¨æ¿å®šç¾©
- Alertmanagerå‘Šè­¦é…ç½®
- ELK Stackéƒ¨ç½²é…ç½®
- ç›£æ§é‹ç¶­æ‰‹å†Š

### ç·´ç¿’3ï¼šç½é›£æ¢å¾©è¨ˆç•«

**æƒ…å¢ƒè¨­å®š**ï¼š
æ¨¡æ“¬ç”Ÿç”¢ç’°å¢ƒç™¼ç”Ÿé‡å¤§æ•…éšœï¼Œéœ€è¦åŸ·è¡Œç½é›£æ¢å¾©ã€‚

**ä»»å‹™3.1ï¼šå‚™ä»½ç­–ç•¥å¯¦æ–½**
å»ºç«‹å®Œæ•´çš„3-2-1å‚™ä»½ç­–ç•¥ï¼š

1. **è‡ªå‹•åŒ–å‚™ä»½è…³æœ¬**
```bash
#!/bin/bash
# å¯¦ä½œæ¯æ—¥ã€æ¯é€±ã€æ¯æœˆå‚™ä»½ç­–ç•¥
# åŒ…å«è³‡æ–™åº«ã€æ‡‰ç”¨ç¨‹å¼ã€é…ç½®æª”æ¡ˆ
```

2. **å‚™ä»½é©—è­‰æ©Ÿåˆ¶**
```bash
#!/bin/bash
# å®šæœŸé©—è­‰å‚™ä»½å®Œæ•´æ€§
# è‡ªå‹•åŒ–æ¢å¾©æ¸¬è©¦
```

3. **é›²ç«¯å‚™ä»½è¨­ç½®**
- AWS S3è·¨å€åŸŸè¤‡è£½
- ç”Ÿå‘½é€±æœŸç®¡ç†ç­–ç•¥
- å­˜å–æ§åˆ¶è¨­å®š

**ä»»å‹™3.2ï¼šç½é›£æ¢å¾©æ¼”ç·´**
è¨­è¨ˆä¸¦åŸ·è¡Œç½é›£æ¢å¾©æ¼”ç·´ï¼š

1. **RTO/RPOç›®æ¨™è¨­å®š**
   - é—œéµæœå‹™ï¼šRTO < 1å°æ™‚ï¼ŒRPO < 15åˆ†é˜
   - ä¸€èˆ¬æœå‹™ï¼šRTO < 4å°æ™‚ï¼ŒRPO < 1å°æ™‚

2. **æ¢å¾©ç¨‹åºæ–‡ä»¶**
   - è©³ç´°æ¢å¾©æ­¥é©Ÿ
   - è§’è‰²èˆ‡è²¬ä»»åˆ†å·¥
   - æºé€šå’Œå‡ç´šæµç¨‹

3. **æ¼”ç·´è…³æœ¬**
```bash
#!/bin/bash
# ç½é›£æ¢å¾©æ¼”ç·´è‡ªå‹•åŒ–è…³æœ¬
# åŒ…å«ç’°å¢ƒé‡å»ºã€è³‡æ–™æ¢å¾©ã€æœå‹™é©—è­‰
```

**ä»»å‹™3.3ï¼šæ¥­å‹™é€£çºŒæ€§è¨ˆç•«**
åˆ¶å®šå®Œæ•´çš„æ¥­å‹™é€£çºŒæ€§è¨ˆç•«ï¼š
- é¢¨éšªè©•ä¼°å’Œå½±éŸ¿åˆ†æ
- å‚™æ´ç­–ç•¥å’Œæ›¿ä»£æ–¹æ¡ˆ
- æºé€šè¨ˆç•«å’Œåˆ©å®³é—œä¿‚äººç®¡ç†
- å®šæœŸå¯©æŸ¥å’Œæ›´æ–°æ©Ÿåˆ¶

**æäº¤æˆæœ**ï¼š
- å‚™ä»½ç­–ç•¥æ–‡ä»¶
- ç½é›£æ¢å¾©æ‰‹å†Š
- æ¼”ç·´å ±å‘Šå’Œæ”¹å–„å»ºè­°
- æ¥­å‹™é€£çºŒæ€§è¨ˆç•«

### ç·´ç¿’4ï¼šä½¿ç”¨è€…æ”¯æ´é«”ç³»å»ºç«‹

**ä»»å‹™4.1ï¼šå¤šå±¤ç´šæ”¯æ´è¨­è¨ˆ**
å»ºç«‹å®Œæ•´çš„ä½¿ç”¨è€…æ”¯æ´é«”ç³»ï¼š

1. **è‡ªåŠ©æœå‹™é–€æˆ¶**
   - çŸ¥è­˜åº«å»ºç«‹
   - å¸¸è¦‹å•é¡ŒFAQ
   - å½±ç‰‡æ•™å­¸åº«
   - æ”¯æ´å·¥å–®ç³»çµ±

2. **èŠå¤©æ©Ÿå™¨äºº**
```javascript
// å»ºç«‹æ™ºèƒ½å®¢æœæ©Ÿå™¨äºº
// å¸¸è¦‹å•é¡Œè‡ªå‹•å›è¦†
// å•é¡Œåˆ†é¡å’Œè·¯ç”±
```

3. **æ”¯æ´æµç¨‹è¨­è¨ˆ**
   - å•é¡Œåˆ†ç´šè™•ç†
   - SLAæ™‚é–“è¨­å®š
   - å‡ç´šæ©Ÿåˆ¶è¨­è¨ˆ

**ä»»å‹™4.2ï¼šAPIæ–‡ä»¶ç³»çµ±**
å»ºç«‹å®Œæ•´çš„æŠ€è¡“æ–‡ä»¶é«”ç³»ï¼š

1. **OpenAPIæ–‡ä»¶ç”Ÿæˆ**
```javascript
// è‡ªå‹•åŒ–APIæ–‡ä»¶ç”Ÿæˆ
// åŒ…å«ç¯„ä¾‹ã€éŒ¯èª¤ç¢¼ã€èªè­‰èªªæ˜
```

2. **äº’å‹•å¼æ–‡ä»¶**
   - Swagger UIè¨­ç½®
   - APIæ¸¬è©¦åŠŸèƒ½
   - SDKä½¿ç”¨ç¯„ä¾‹

3. **æ–‡ä»¶ç™¼å¸ƒæµç¨‹**
```yaml
# CI/CDè‡ªå‹•åŒ–æ–‡ä»¶ç™¼å¸ƒ
# ç‰ˆæœ¬æ§åˆ¶å’Œæ­·å²ä¿å­˜
```

**ä»»å‹™4.3ï¼šæ”¯æ´æŒ‡æ¨™è¿½è¹¤**
å»ºç«‹æ”¯æ´å“è³ªæŒ‡æ¨™ç³»çµ±ï¼š
- å›æ‡‰æ™‚é–“ç›£æ§
- è§£æ±ºç‡çµ±è¨ˆ
- ä½¿ç”¨è€…æ»¿æ„åº¦èª¿æŸ¥
- æ”¯æ´æˆæœ¬åˆ†æ

**æäº¤æˆæœ**ï¼š
- æ”¯æ´é«”ç³»è¨­è¨ˆæ–‡ä»¶
- è‡ªåŠ©æœå‹™é–€æˆ¶åŸå‹
- APIæ–‡ä»¶ç³»çµ±
- æ”¯æ´æŒ‡æ¨™å„€è¡¨æ¿

---

## ğŸ“ çŸ¥è­˜æª¢æ ¸æ¸¬é©—

### é¸æ“‡é¡Œ (æ¯é¡Œ5åˆ†ï¼Œå…±50åˆ†)

**1. è—ç¶ éƒ¨ç½²çš„ä¸»è¦å„ªå‹¢æ˜¯ä»€éº¼ï¼Ÿ**
A) ç¯€çœä¼ºæœå™¨æˆæœ¬
B) å¯¦ç¾é›¶åœæ©Ÿéƒ¨ç½²
C) ç°¡åŒ–é–‹ç™¼æµç¨‹
D) æ¸›å°‘ç¨‹å¼ç¢¼è¤‡é›œåº¦

**2. RTOå’ŒRPOåˆ†åˆ¥ä»£è¡¨ä»€éº¼ï¼Ÿ**
A) ä¿®å¾©æ™‚é–“å’Œå¾©åŸé»
B) é‹è¡Œæ™‚é–“å’Œæ•ˆèƒ½é»
C) å›æ‡‰æ™‚é–“å’Œè™•ç†é»
D) å¯é æ™‚é–“å’Œæ•ˆç‡é»

**3. 3-2-1å‚™ä»½ç­–ç•¥ä¸­çš„"3"æŒ‡çš„æ˜¯ä»€éº¼ï¼Ÿ**
A) 3å€‹å‚™ä»½ä½ç½®
B) 3ç¨®å‚™ä»½æ–¹æ³•
C) 3ä»½è³‡æ–™å‰¯æœ¬
D) 3å¤©å‚™ä»½é€±æœŸ

**4. Prometheusä¸»è¦ç”¨æ–¼ä»€éº¼ï¼Ÿ**
A) ç¨‹å¼ç¢¼ç‰ˆæœ¬æ§åˆ¶
B) ç³»çµ±ç›£æ§å’Œå‘Šè­¦
C) è‡ªå‹•åŒ–éƒ¨ç½²
D) è³‡æ–™åº«ç®¡ç†

**5. é‡‘çµ²é›€éƒ¨ç½²çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ä»€éº¼ï¼Ÿ**
A) å®Œå…¨æ›¿æ›èˆŠç‰ˆæœ¬
B) åŒæ™‚é‹è¡Œå…©å€‹ç‰ˆæœ¬
C) æ¼¸é€²å¼æµé‡åˆ†é…
D) å®šæ™‚è‡ªå‹•æ›´æ–°

**6. ç½é›£æ¢å¾©æ¼”ç·´çš„ä¸»è¦ç›®çš„æ˜¯ä»€éº¼ï¼Ÿ**
A) æ¸¬è©¦å‚™ä»½å®Œæ•´æ€§
B) é©—è­‰æ¢å¾©æµç¨‹
C) æª¢æŸ¥ç³»çµ±æ•ˆèƒ½
D) è¨“ç·´æŠ€è¡“äººå“¡

**7. æŠ€è¡“å‚µå‹™ç®¡ç†çš„é¦–è¦åŸå‰‡æ˜¯ä»€éº¼ï¼Ÿ**
A) ç«‹å³ä¿®å¾©æ‰€æœ‰å•é¡Œ
B) æ ¹æ“šå½±éŸ¿å’Œå„ªå…ˆç´šè™•ç†
C) å¿½ç•¥éºç•™ç³»çµ±å•é¡Œ
D) ç­‰å¾…ç³»çµ±é‡å¯«

**8. SLAä¸­æœ€é‡è¦çš„æŒ‡æ¨™é€šå¸¸æ˜¯ä»€éº¼ï¼Ÿ**
A) ç³»çµ±åŠŸèƒ½æ•¸é‡
B) å¯ç”¨æ€§ç™¾åˆ†æ¯”
C) ä½¿ç”¨è€…æ•¸é‡
D) ç¨‹å¼ç¢¼å“è³ª

**9. çµæ®ºè€…æ¨¡å¼ä¸»è¦ç”¨æ–¼ä»€éº¼å ´æ™¯ï¼Ÿ**
A) æ–°ç³»çµ±é–‹ç™¼
B) æ•ˆèƒ½å„ªåŒ–
C) éºç•™ç³»çµ±ç¾ä»£åŒ–
D) å®‰å…¨æ€§åŠ å¼·

**10. è»Ÿé«”ç¶­è­·æˆæœ¬é€šå¸¸å æ•´å€‹ç”Ÿå‘½é€±æœŸæˆæœ¬çš„å¤šå°‘ï¼Ÿ**
A) 30%
B) 50%
C) 70%
D) 90%

### ç°¡ç­”é¡Œ (æ¯é¡Œ25åˆ†ï¼Œå…±50åˆ†)

**1. è«‹èªªæ˜è—ç¶ éƒ¨ç½²ã€é‡‘çµ²é›€éƒ¨ç½²å’Œæ»¾å‹•æ›´æ–°ä¸‰ç¨®éƒ¨ç½²ç­–ç•¥çš„å·®ç•°ï¼Œä¸¦åˆ†æå„è‡ªçš„é©ç”¨å ´æ™¯å’Œå„ªç¼ºé»ã€‚(300å­—)**

**2. æè¿°ä¸€å€‹å®Œæ•´çš„ç½é›£æ¢å¾©è¨ˆç•«æ‡‰è©²åŒ…å«å“ªäº›è¦ç´ ï¼Ÿå¦‚ä½•ç¢ºä¿ç½é›£æ¢å¾©è¨ˆç•«çš„æœ‰æ•ˆæ€§ï¼Ÿè«‹æä¾›å…·é«”çš„å¯¦æ–½å»ºè­°ã€‚(300å­—)**

---

## ğŸ“š å»¶ä¼¸å­¸ç¿’è³‡æº

### å¿…è®€æ›¸ç±
1. **ã€ŠSite Reliability Engineeringã€‹** - Google SRE Team
2. **ã€ŠThe DevOps Handbookã€‹** - Gene Kim, Jez Humble
3. **ã€ŠContinuous Deliveryã€‹** - Jez Humble, David Farley
4. **ã€ŠInfrastructure as Codeã€‹** - Kief Morris
5. **ã€ŠMonitoring and Observabilityã€‹** - Cindy Sridharan

### ç·šä¸Šèª²ç¨‹
1. **AWS Solutions Architect** - é›²ç«¯æ¶æ§‹èˆ‡éƒ¨ç½²
2. **Kubernetes Administrator (CKA)** - å®¹å™¨ç·¨æ’ç®¡ç†
3. **Prometheus Monitoring** - ç³»çµ±ç›£æ§å¯¦å‹™
4. **Disaster Recovery Planning** - ç½é›£æ¢å¾©è¦åŠƒ

### å¯¦ç”¨å·¥å…·
1. **éƒ¨ç½²å·¥å…·**ï¼š
   - Kubernetes - å®¹å™¨ç·¨æ’å¹³å°
   - Helm - Kuberneteså¥—ä»¶ç®¡ç†
   - ArgoCD - GitOpsæŒçºŒéƒ¨ç½²
   - Spinnaker - å¤šé›²éƒ¨ç½²å¹³å°

2. **ç›£æ§å·¥å…·**ï¼š
   - Prometheus - ç›£æ§å’Œå‘Šè­¦
   - Grafana - è¦–è¦ºåŒ–å„€è¡¨æ¿
   - Jaeger - åˆ†æ•£å¼è¿½è¹¤
   - ELK Stack - æ—¥èªŒç®¡ç†

3. **åŸºç¤è¨­æ–½å·¥å…·**ï¼š
   - Terraform - åŸºç¤è¨­æ–½å³ä»£ç¢¼
   - Ansible - é…ç½®ç®¡ç†
   - Packer - æ˜ åƒå»ºç½®
   - Vault - ç§˜å¯†ç®¡ç†

4. **é›²ç«¯å¹³å°**ï¼š
   - AWS - äºé¦¬éœé›²ç«¯æœå‹™
   - Azure - å¾®è»Ÿé›²ç«¯å¹³å°
   - GCP - Googleé›²ç«¯å¹³å°
   - DigitalOcean - ç°¡åŒ–é›²ç«¯æœå‹™

### èªè­‰èˆ‡ç¤¾ç¾¤
1. **å°ˆæ¥­èªè­‰**ï¼š
   - AWS Certified Solutions Architect
   - Certified Kubernetes Administrator
   - Google Cloud Professional DevOps Engineer
   - Microsoft Azure DevOps Engineer

2. **æŠ€è¡“ç¤¾ç¾¤**ï¼š
   - CNCF (Cloud Native Computing Foundation)
   - DevOpså°ç£ç¤¾ç¾¤
   - SRE Taiwan
   - Kubernetes Taiwan User Group

---

## âœ… å­¸ç¿’æª¢æ ¸è¡¨

- [ ] ç†è§£ç¾ä»£è»Ÿé«”éƒ¨ç½²ç­–ç•¥å’Œæœ€ä½³å¯¦å‹™
- [ ] æŒæ¡å¤šç’°å¢ƒéƒ¨ç½²æ¶æ§‹è¨­è¨ˆ
- [ ] ç†Ÿæ‚‰è—ç¶ ã€é‡‘çµ²é›€ã€æ»¾å‹•æ›´æ–°éƒ¨ç½²æ–¹æ³•
- [ ] èƒ½å»ºç«‹å®Œæ•´çš„CI/CDè‡ªå‹•åŒ–æµç¨‹
- [ ] äº†è§£ç³»çµ±ç›£æ§å’Œå‘Šè­¦æ©Ÿåˆ¶
- [ ] æŒæ¡Prometheuså’ŒGrafanaä½¿ç”¨
- [ ] èƒ½è¨­è¨ˆæœ‰æ•ˆçš„å‚™ä»½å’Œæ¢å¾©ç­–ç•¥
- [ ] ç†è§£ç½é›£æ¢å¾©è¨ˆç•«çš„é‡è¦æ€§
- [ ] äº†è§£æŠ€è¡“å‚µå‹™ç®¡ç†æ–¹æ³•
- [ ] èƒ½å»ºç«‹ä½¿ç”¨è€…æ”¯æ´é«”ç³»
- [ ] æŒæ¡APIæ–‡ä»¶è‡ªå‹•åŒ–ç”Ÿæˆ
- [ ] ç†è§£è»Ÿé«”ç”Ÿå‘½é€±æœŸç®¡ç†
- [ ] å®Œæˆæ‰€æœ‰å¯¦å‹™ç·´ç¿’
- [ ] é€šéçŸ¥è­˜æª¢æ ¸æ¸¬é©— (70åˆ†ä»¥ä¸Š)

---

## ğŸ“ èª²ç¨‹ç¸½çµèˆ‡å±•æœ›

### ğŸ“Š å­¸ç¿’æ­·ç¨‹å›é¡§

æ­å–œæ‚¨å®Œæˆäº†å®Œæ•´çš„è»Ÿé«”é–‹ç™¼ç”Ÿå‘½é€±æœŸ (SDLC) è‡ªä¸»è¨“ç·´èª²ç¨‹ï¼è®“æˆ‘å€‘å›é¡§é€™8é€±çš„å­¸ç¿’æ­·ç¨‹ï¼š

**ç¬¬ä¸€æ¨¡çµ„ï¼šSDLCåŸºç¤æ¦‚å¿µ** âœ…
- å»ºç«‹è»Ÿé«”å·¥ç¨‹æ€ç¶­
- ç†è§£é–‹ç™¼éç¨‹çš„è¤‡é›œæ€§
- èªè­˜å“è³ªä¿è­‰çš„é‡è¦æ€§

**ç¬¬äºŒæ¨¡çµ„ï¼šSDLCæ¨¡å‹èˆ‡æ–¹æ³•è«–** âœ…
- æŒæ¡å‚³çµ±èˆ‡æ•æ·é–‹ç™¼æ¨¡å‹
- å­¸æœƒé¸æ“‡é©åˆçš„é–‹ç™¼æ–¹æ³•
- å»ºç«‹DevOpsæ–‡åŒ–èªçŸ¥

**ç¬¬ä¸‰æ¨¡çµ„ï¼šéœ€æ±‚åˆ†æèˆ‡è¦æ ¼æ’°å¯«** âœ…
- æŒæ¡éœ€æ±‚å·¥ç¨‹æ ¸å¿ƒæŠ€èƒ½
- å­¸æœƒæ’°å¯«å°ˆæ¥­éœ€æ±‚æ–‡ä»¶
- å»ºç«‹éœ€æ±‚ç®¡ç†æµç¨‹

**ç¬¬å››æ¨¡çµ„ï¼šç³»çµ±è¨­è¨ˆèˆ‡æ¶æ§‹** âœ…
- å­¸æœƒç³»çµ±åŒ–è¨­è¨ˆæ€ç¶­
- æŒæ¡UMLå»ºæ¨¡æŠ€å·§
- å»ºç«‹æ¶æ§‹æ±ºç­–èƒ½åŠ›

**ç¬¬äº”æ¨¡çµ„ï¼šç¨‹å¼é–‹ç™¼èˆ‡å¯¦ä½œ** âœ…
- å»ºç«‹å°ˆæ¥­ç·¨ç¢¼æ¨™æº–
- æŒæ¡ç‰ˆæœ¬æ§åˆ¶æœ€ä½³å¯¦å‹™
- å­¸æœƒç¨‹å¼ç¢¼å“è³ªç®¡ç†

**ç¬¬å…­æ¨¡çµ„ï¼šè»Ÿé«”æ¸¬è©¦** âœ…
- å»ºç«‹å…¨é¢æ¸¬è©¦æ€ç¶­
- æŒæ¡è‡ªå‹•åŒ–æ¸¬è©¦æŠ€èƒ½
- å­¸æœƒTDDé–‹ç™¼æ–¹æ³•

**ç¬¬ä¸ƒæ¨¡çµ„ï¼šéƒ¨ç½²èˆ‡ç¶­è­·** âœ…
- æŒæ¡ç¾ä»£éƒ¨ç½²ç­–ç•¥
- å»ºç«‹ç›£æ§å’Œç¶­è­·é«”ç³»
- å­¸æœƒç½é›£æ¢å¾©è¦åŠƒ

### ğŸš€ æ ¸å¿ƒèƒ½åŠ›ç²å¾—

é€šéé€™å€‹èª²ç¨‹ï¼Œæ‚¨å·²ç¶“å…·å‚™äº†ï¼š

**æŠ€è¡“èƒ½åŠ›**ï¼š
- å®Œæ•´çš„SDLCæµç¨‹æŒæ¡
- ç¾ä»£é–‹ç™¼å·¥å…·éˆä½¿ç”¨
- è‡ªå‹•åŒ–æ¸¬è©¦å’Œéƒ¨ç½²æŠ€èƒ½
- ç³»çµ±ç›£æ§å’Œç¶­è­·èƒ½åŠ›

**è»ŸæŠ€èƒ½**ï¼š
- ç³»çµ±åŒ–æ€è€ƒèƒ½åŠ›
- å•é¡Œåˆ†æå’Œè§£æ±ºæŠ€å·§
- åœ˜éšŠå”ä½œå’Œæºé€šèƒ½åŠ›
- æŒçºŒå­¸ç¿’å’Œæ”¹å–„æ„è­˜

**ç®¡ç†èƒ½åŠ›**ï¼š
- å°ˆæ¡ˆè¦åŠƒå’ŒåŸ·è¡Œ
- é¢¨éšªè­˜åˆ¥å’Œæ§åˆ¶
- å“è³ªä¿è­‰å’Œæµç¨‹å„ªåŒ–
- åœ˜éšŠæŒ‡å°å’ŒçŸ¥è­˜å‚³æ‰¿

### ğŸ¯ è·æ¶¯ç™¼å±•è·¯å¾‘

åŸºæ–¼æ‚¨æ‰€å­¸çš„æŠ€èƒ½ï¼Œå¯ä»¥è€ƒæ…®ä»¥ä¸‹è·æ¶¯ç™¼å±•æ–¹å‘ï¼š

**æŠ€è¡“å°ˆå®¶è·¯ç·š**ï¼š
- **è³‡æ·±è»Ÿé«”å·¥ç¨‹å¸«** â†’ **æŠ€è¡“æ¶æ§‹å¸«** â†’ **é¦–å¸­æŠ€è¡“å®˜**
- **é‡é»æŠ€èƒ½**ï¼šæ·±åº¦æŠ€è¡“å°ˆç²¾ã€æ¶æ§‹è¨­è¨ˆã€æŠ€è¡“æ±ºç­–

**ç”¢å“é–‹ç™¼è·¯ç·š**ï¼š
- **å…¨ç«¯é–‹ç™¼å·¥ç¨‹å¸«** â†’ **ç”¢å“ç¶“ç†** â†’ **ç”¢å“ç¸½ç›£**
- **é‡é»æŠ€èƒ½**ï¼šè·¨é ˜åŸŸæ•´åˆã€ä½¿ç”¨è€…æ€ç¶­ã€ç”¢å“ç­–ç•¥

**è³ªé‡ä¿è­‰è·¯ç·š**ï¼š
- **æ¸¬è©¦å·¥ç¨‹å¸«** â†’ **QAä¸»ç®¡** â†’ **è³ªé‡ç¸½ç›£**
- **é‡é»æŠ€èƒ½**ï¼šæ¸¬è©¦ç­–ç•¥ã€æµç¨‹å„ªåŒ–ã€å“è³ªæ–‡åŒ–

**é‹ç¶­ç®¡ç†è·¯ç·š**ï¼š
- **DevOpså·¥ç¨‹å¸«** â†’ **SREå·¥ç¨‹å¸«** â†’ **æŠ€è¡“é‹ç‡Ÿç¸½ç›£**
- **é‡é»æŠ€èƒ½**ï¼šè‡ªå‹•åŒ–ã€ç›£æ§ã€å¯é æ€§å·¥ç¨‹

### ğŸ“ˆ æŒçºŒå­¸ç¿’å»ºè­°

**çŸ­æœŸç›®æ¨™ (3-6å€‹æœˆ)**ï¼š
- åœ¨å¯¦éš›å°ˆæ¡ˆä¸­æ‡‰ç”¨æ‰€å­¸æŠ€èƒ½
- æ·±åŒ–ç‰¹å®šé ˜åŸŸçš„å°ˆæ¥­çŸ¥è­˜
- åƒèˆ‡é–‹æºå°ˆæ¡ˆè²¢ç»
- å–å¾—ç›¸é—œæŠ€è¡“èªè­‰

**ä¸­æœŸç›®æ¨™ (1-2å¹´)**ï¼š
- å»ºç«‹å€‹äººæŠ€è¡“å“ç‰Œ
- æˆç‚ºåœ˜éšŠä¸­çš„æŠ€è¡“å°å¸«
- è·¨é ˜åŸŸçŸ¥è­˜æ•´åˆ
- é ˜å°å°å‹å°ˆæ¡ˆ

**é•·æœŸç›®æ¨™ (3-5å¹´)**ï¼š
- ç™¼å±•æ¶æ§‹å¸«æˆ–ç®¡ç†èƒ½åŠ›
- å»ºç«‹è¡Œæ¥­å½±éŸ¿åŠ›
- å‰µæ–°æŠ€è¡“æ‡‰ç”¨
- åŸ¹é¤Šä¸‹ä¸€ä»£æŠ€è¡“äººæ‰

### ğŸŒŸ å­¸ç¿’å¿ƒæ…‹èˆ‡æ–¹æ³•

**ä¿æŒå¥½å¥‡å¿ƒ**ï¼š
- æŒçºŒé—œæ³¨æŠ€è¡“è¶¨å‹¢
- å˜—è©¦æ–°å·¥å…·å’Œæ–¹æ³•
- åƒèˆ‡æŠ€è¡“ç¤¾ç¾¤è¨è«–
- å®šæœŸåæ€å’Œèª¿æ•´

**å¯¦è¸å°å‘**ï¼š
- å°‡ç†è«–æ‡‰ç”¨åˆ°å¯¦éš›å°ˆæ¡ˆ
- å»ºç«‹å€‹äººå°ˆæ¡ˆä½œå“é›†
- è¨˜éŒ„å­¸ç¿’éç¨‹å’Œå¿ƒå¾—
- åˆ†äº«ç¶“é©—å¹«åŠ©ä»–äºº

**ç³»çµ±æ€è€ƒ**ï¼š
- å¾æ•´é«”è§’åº¦çœ‹å¾…å•é¡Œ
- ç†è§£å„å€‹ç’°ç¯€çš„é—œè¯
- å¹³è¡¡æŠ€è¡“å’Œæ¥­å‹™éœ€æ±‚
- è€ƒæ…®é•·æœŸç¶­è­·æˆæœ¬

---

## ğŸ”® æœªä¾†æŠ€è¡“è¶¨å‹¢

### ğŸ¤– å€¼å¾—é—œæ³¨çš„æŠ€è¡“æ–¹å‘

**äººå·¥æ™ºæ…§èˆ‡æ©Ÿå™¨å­¸ç¿’**ï¼š
- AIè¼”åŠ©è»Ÿé«”é–‹ç™¼
- æ™ºèƒ½æ¸¬è©¦å’Œé™¤éŒ¯
- è‡ªå‹•åŒ–ç¨‹å¼ç¢¼ç”Ÿæˆ
- é æ¸¬æ€§ç¶­è­·

**é›²åŸç”ŸæŠ€è¡“**ï¼š
- Serverlessæ¶æ§‹
- å¾®æœå‹™æ²»ç†
- æœå‹™ç¶²æ ¼ (Service Mesh)
- é‚Šç·£è¨ˆç®—

**ä½ç¨‹å¼ç¢¼/ç„¡ç¨‹å¼ç¢¼**ï¼š
- è¦–è¦ºåŒ–é–‹ç™¼å¹³å°
- APIå„ªå…ˆè¨­è¨ˆ
- å…¬æ°‘é–‹ç™¼è€…è³¦èƒ½
- å¿«é€ŸåŸå‹é–‹ç™¼

**å®‰å…¨èˆ‡éš±ç§**ï¼š
- DevSecOpsæ•´åˆ
- é›¶ä¿¡ä»»æ¶æ§‹
- éš±ç§ä¿è­·æŠ€è¡“
- åˆè¦è‡ªå‹•åŒ–

### ğŸ“ æ¨è–¦æ·±åº¦å­¸ç¿’é ˜åŸŸ

**é¸æ“‡å»ºè­°**ï¼šæ ¹æ“šå€‹äººèˆˆè¶£å’Œè·æ¶¯ç›®æ¨™ï¼Œå»ºè­°é¸æ“‡1-2å€‹é ˜åŸŸé€²è¡Œæ·±åº¦å­¸ç¿’ï¼š

1. **é›²ç«¯æ¶æ§‹èˆ‡DevOps**
2. **å‰ç«¯æŠ€è¡“èˆ‡ä½¿ç”¨è€…é«”é©—**
3. **å¾Œç«¯ç³»çµ±èˆ‡è³‡æ–™å·¥ç¨‹**
4. **è¡Œå‹•æ‡‰ç”¨èˆ‡è·¨å¹³å°é–‹ç™¼**
5. **äººå·¥æ™ºæ…§èˆ‡æ©Ÿå™¨å­¸ç¿’**
6. **è³‡è¨Šå®‰å…¨èˆ‡éš±ç§ä¿è­·**

---

## ğŸ’¬ çµèªèˆ‡æ„Ÿè¬

æ„Ÿè¬æ‚¨å®Œæˆé€™å€‹å®Œæ•´çš„SDLCè‡ªä¸»è¨“ç·´èª²ç¨‹ï¼é€™8é€±çš„å­¸ç¿’æ­·ç¨‹ä¸åƒ…æ˜¯çŸ¥è­˜çš„ç´¯ç©ï¼Œæ›´æ˜¯æ€ç¶­æ–¹å¼çš„è½‰è®Šå’Œå°ˆæ¥­èƒ½åŠ›çš„æå‡ã€‚

**è¨˜ä½**ï¼š
- è»Ÿé«”é–‹ç™¼æ˜¯ä¸€å€‹ä¸æ–·å­¸ç¿’å’Œé€²æ­¥çš„éç¨‹
- ç†è«–èˆ‡å¯¦å‹™çš„çµåˆæ˜¯æˆåŠŸçš„é—œéµ
- åœ˜éšŠå”ä½œæ¯”å€‹äººæŠ€èƒ½æ›´é‡è¦
- æŒçºŒæ”¹å–„æ˜¯å°ˆæ¥­æˆé•·çš„å‹•åŠ›

**ä¸‹ä¸€æ­¥è¡Œå‹•å»ºè­°**ï¼š
1. é¸æ“‡ä¸€å€‹å¯¦éš›å°ˆæ¡ˆæ‡‰ç”¨æ‰€å­¸æŠ€èƒ½
2. åŠ å…¥æŠ€è¡“ç¤¾ç¾¤åˆ†äº«å­¸ç¿’å¿ƒå¾—
3. åˆ¶å®šå€‹äººå­¸ç¿’å’Œè·æ¶¯ç™¼å±•è¨ˆç•«
4. æŒçºŒé—œæ³¨æŠ€è¡“è¶¨å‹¢å’Œæœ€ä½³å¯¦å‹™

**æœ€å¾Œçš„ç¥ç¦**ï¼š
é¡˜æ‚¨åœ¨è»Ÿé«”é–‹ç™¼çš„é“è·¯ä¸ŠæŒçºŒæˆé•·ï¼Œç”¨æŠ€è¡“æ”¹è®Šä¸–ç•Œï¼Œç”¨ä»£ç¢¼å‰µé€ åƒ¹å€¼ï¼

## ğŸŒŸ å­¸ç¿’åæ€

è«‹èŠ±15åˆ†é˜å®Œæˆæœ€çµ‚åæ€ï¼š

1. **æœ€å¤§æ”¶ç©«**ï¼šé€™8é€±å­¸ç¿’ä¸­æœ€å¯¶è²´çš„æ”¶ç©«æ˜¯ä»€éº¼ï¼Ÿ
2. **å¯¦å‹™æ‡‰ç”¨**ï¼šæ‚¨è¨ˆç•«å¦‚ä½•å°‡æ‰€å­¸æ‡‰ç”¨åˆ°å¯¦éš›å·¥ä½œä¸­ï¼Ÿ
3. **æŠ€èƒ½ç¼ºå£**ï¼šé‚„æœ‰å“ªäº›æŠ€èƒ½éœ€è¦é€²ä¸€æ­¥åŠ å¼·ï¼Ÿ
4. **è·æ¶¯è¦åŠƒ**ï¼šæœªä¾†1-2å¹´çš„å­¸ç¿’å’Œè·æ¶¯ç›®æ¨™æ˜¯ä»€éº¼ï¼Ÿ
5. **æŒçºŒæ”¹å–„**ï¼šå¦‚ä½•å»ºç«‹æŒçºŒå­¸ç¿’å’Œæ”¹å–„çš„ç¿’æ…£ï¼Ÿ

---

**ğŸ‰ å†æ¬¡æ­å–œæ‚¨å®ŒæˆSDLCè‡ªä¸»è¨“ç·´èª²ç¨‹ï¼**  
*æ‚¨ç¾åœ¨å·²ç¶“å…·å‚™äº†ç¾ä»£è»Ÿé«”é–‹ç™¼çš„å®Œæ•´æŠ€èƒ½ï¼Œæº–å‚™å¥½åœ¨æŠ€è¡“é ˜åŸŸç™¼å…‰ç™¼ç†±äº†ï¼*

**ç¥æ‚¨åœ¨è»Ÿé«”é–‹ç™¼çš„é“è·¯ä¸Šä¸€å¸†é¢¨é †ï¼Œå‰ç¨‹ä¼¼éŒ¦ï¼** ğŸš€âœ¨